{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:09:59.358591Z","iopub.execute_input":"2025-11-05T17:09:59.358817Z","iopub.status.idle":"2025-11-05T17:11:17.708281Z","shell.execute_reply.started":"2025-11-05T17:09:59.358794Z","shell.execute_reply":"2025-11-05T17:11:17.707502Z"}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.1->monai)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.1->monai)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.1->monai)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.1->monai)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.1->monai)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.1->monai)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.1->monai)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nDownloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed monai-1.5.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom monai.networks.nets.swin_unetr import SwinTransformer\nimport torch.nn.functional as F\nfrom typing import List, Optional, Tuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:11:17.710031Z","iopub.execute_input":"2025-11-05T17:11:17.710290Z","iopub.status.idle":"2025-11-05T17:11:48.206577Z","shell.execute_reply.started":"2025-11-05T17:11:17.710270Z","shell.execute_reply":"2025-11-05T17:11:48.205873Z"}},"outputs":[{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-11-05 17:11:35.402812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762362695.576149      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762362695.626166      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class AttentionFaultFormerEncoder(nn.Module):\n    \"\"\"\n    Обёртка над MONAI SwinTransformer, возвращающая ровно 3 cascaded stages.\n    Заменяет encoder.patch_embed.proj на Conv3d(kernel=5, stride=2, padding=2).\n    Важно: используемую версию MONAI должна содержать SwinTransformer и\n    атрибут encoder.patch_embed.proj.\n    \"\"\"\n    def __init__(\n        self,\n        in_chans: int = 1,\n        embed_dim: int = 48,\n        window_size=(7,7,7),\n        patch_size=(2,2,2),\n        depths=(2,2,2,1),           \n        num_heads=(3,6,12,12),\n        mlp_ratio: float = 4.0,\n        qkv_bias: bool = True,\n        drop_rate: float = 0.0,\n        attn_drop_rate: float = 0.0,\n        drop_path_rate: float = 0.1,\n        norm_layer=nn.LayerNorm,\n        patch_norm: bool = True,\n        use_checkpoint: bool = True,\n        spatial_dims: int = 3,\n        patch_kernel: int = 5,\n        patch_stride: int = 2,\n        patch_padding: int = 2,\n    ):\n        super().__init__()\n        if SwinTransformer is None:\n            raise ImportError(\"MONAI SwinTransformer не найден. Установите monai>=0.x и убедитесь, что модуль swin_unetr доступен.\")\n\n        # создаём стандартный SwinTransformer (MONAI)\n        self.encoder = SwinTransformer(\n            in_chans=in_chans,\n            embed_dim=embed_dim,\n            window_size=window_size,\n            patch_size=patch_size,\n            depths=depths,\n            num_heads=num_heads,\n            mlp_ratio=mlp_ratio,\n            qkv_bias=qkv_bias,\n            drop_rate=drop_rate,\n            attn_drop_rate=attn_drop_rate,\n            drop_path_rate=drop_path_rate,\n            norm_layer=norm_layer,\n            patch_norm=patch_norm,\n            use_checkpoint=use_checkpoint,\n            spatial_dims=spatial_dims,\n        )\n\n        # заменяем внутр. проекцию patch-embed на Conv3d(kernel=5, stride=2, padding=2)\n        self.encoder.patch_embed.proj = nn.Conv3d(\n            in_channels=in_chans,\n            out_channels=embed_dim,\n            kernel_size=patch_kernel,\n            stride=patch_stride,\n            padding=patch_padding,\n            bias=False,\n        )\n        nn.init.kaiming_normal_(self.encoder.patch_embed.proj.weight, nonlinearity=\"relu\")\n  \n\n    def forward(self, x: torch.Tensor) -> List[torch.Tensor]:\n        \"\"\"\n        Возвращает список фичей [stage1, stage2, stage3]\n        (берём из возвращаемого MONAI списка элементы 1..3).\n        \"\"\"\n        feats = self.encoder(x)\n        # В статье используются 3 стадии; берем feats[1], feats[2], feats[3]\n        return [feats[1], feats[2], feats[3]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:14.831098Z","iopub.execute_input":"2025-11-05T17:52:14.831989Z","iopub.status.idle":"2025-11-05T17:52:14.840301Z","shell.execute_reply.started":"2025-11-05T17:52:14.831931Z","shell.execute_reply":"2025-11-05T17:52:14.839491Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class ChannelAttention3D(nn.Module):\n    \"\"\"\n    Канальное внимание для 3D фич (часть CBAM).\n    Считает маску каналов через MLP, применяемый к avg/max pooled дескрипторам.\n    \"\"\"\n    def __init__(self, channels: int, reduction_ratio: int = 4):\n        super().__init__()\n        hidden = max(1, channels // reduction_ratio)\n        self.mlp = nn.Sequential(\n            nn.Conv3d(channels, hidden, kernel_size=1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(hidden, channels, kernel_size=1, bias=False)\n        )\n        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n        self.max_pool = nn.AdaptiveMaxPool3d(1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        avg = self.avg_pool(x)\n        max_ = self.max_pool(x)\n        avg_out = self.mlp(avg)\n        max_out = self.mlp(max_)\n        return self.sigmoid(avg_out + max_out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:15.096503Z","iopub.execute_input":"2025-11-05T17:52:15.097022Z","iopub.status.idle":"2025-11-05T17:52:15.102607Z","shell.execute_reply.started":"2025-11-05T17:52:15.096991Z","shell.execute_reply":"2025-11-05T17:52:15.101978Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class SpatialAttention3D(nn.Module):\n    \"\"\"\n    Пространственное внимание для 3D: объединяет среднее и максимум по каналам\n    и применяет свёртку.\n    \"\"\"\n    def __init__(self, kernel_size: int = 7):\n        super().__init__()\n        padding = (kernel_size - 1) // 2\n        self.conv = nn.Conv3d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        avg = torch.mean(x, dim=1, keepdim=True)\n        max_ = torch.max(x, dim=1, keepdim=True)[0]\n        cat = torch.cat([avg, max_], dim=1)\n        return self.sigmoid(self.conv(cat))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:15.206026Z","iopub.execute_input":"2025-11-05T17:52:15.206231Z","iopub.status.idle":"2025-11-05T17:52:15.211501Z","shell.execute_reply.started":"2025-11-05T17:52:15.206216Z","shell.execute_reply":"2025-11-05T17:52:15.210828Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class CBAM3D(nn.Module):\n    \"\"\"\n    CBAM для 3D: каналное внимание, затем пространственное внимание.\n    \"\"\"\n    def __init__(self, channels: int, reduction_ratio: int = 4, spatial_kernel: int = 7, apply_spatial: bool = True):\n        super().__init__()\n        self.channel_attn = ChannelAttention3D(channels, reduction_ratio)\n        self.apply_spatial = apply_spatial\n        self.spatial_attn = SpatialAttention3D(kernel_size=spatial_kernel)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = x * self.channel_attn(x)\n        if self.apply_spatial:\n            x = x * self.spatial_attn(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:15.427118Z","iopub.execute_input":"2025-11-05T17:52:15.427711Z","iopub.status.idle":"2025-11-05T17:52:15.432473Z","shell.execute_reply.started":"2025-11-05T17:52:15.427688Z","shell.execute_reply":"2025-11-05T17:52:15.431684Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class AttentionSkipBlock(nn.Module):\n    \"\"\"\n    Conv3d(5x5x5) -> CBAM -> BatchNorm3d -> ReLU.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, reduction_ratio: int = 4, apply_spatial: bool = True):\n        super().__init__()\n        self.proj = nn.Conv3d(in_channels, out_channels, kernel_size=5, padding=2, bias=False)\n        self.cbam = CBAM3D(out_channels, reduction_ratio=reduction_ratio, apply_spatial=apply_spatial)\n        self.bn = nn.BatchNorm3d(out_channels)\n        self.act = nn.ReLU(inplace=True)\n        nn.init.kaiming_normal_(self.proj.weight, nonlinearity=\"relu\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.proj(x)\n        x = self.cbam(x)\n        x = self.bn(x)\n        return self.act(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:15.561617Z","iopub.execute_input":"2025-11-05T17:52:15.562341Z","iopub.status.idle":"2025-11-05T17:52:15.567844Z","shell.execute_reply.started":"2025-11-05T17:52:15.562316Z","shell.execute_reply":"2025-11-05T17:52:15.567073Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class MASCA3D(nn.Module):\n    \"\"\"\n    MASCA: полосатые свёртки разной длины с суммированием и 1x1 свёрткой,\n    затем сигмоида для получения воксельной маски.\n    \"\"\"\n    def __init__(self, channels: int, N_list: Tuple[int, ...] = (7, 11)):\n        super().__init__()\n        self.f1_conv = nn.Conv3d(channels, channels, kernel_size=5, padding=2, bias=False)\n        self.N_list = list(N_list)\n        self.strip_blocks = nn.ModuleList()\n        for N in self.N_list:\n            pad = (N - 1) // 2\n            block = nn.Sequential(\n                nn.Conv3d(channels, channels, kernel_size=(1,1,N), padding=(0,0,pad), bias=False),\n                nn.ReLU(inplace=True),\n                nn.Conv3d(channels, channels, kernel_size=(1,N,1), padding=(0,pad,0), bias=False),\n                nn.ReLU(inplace=True),\n                nn.Conv3d(channels, channels, kernel_size=(N,1,1), padding=(pad,0,0), bias=False),\n                nn.ReLU(inplace=True),\n            )\n            self.strip_blocks.append(block)\n        self.out_conv = nn.Conv3d(channels, channels, kernel_size=1, bias=False)\n        self.sigmoid = nn.Sigmoid()\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        f1 = self.f1_conv(x)\n        summ = f1\n        for block in self.strip_blocks:\n            summ = summ + block(f1)\n        w = self.out_conv(summ)\n        w = self.sigmoid(w)\n        return x * w","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:20.457048Z","iopub.execute_input":"2025-11-05T17:52:20.457536Z","iopub.status.idle":"2025-11-05T17:52:20.465405Z","shell.execute_reply.started":"2025-11-05T17:52:20.457514Z","shell.execute_reply":"2025-11-05T17:52:20.464700Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class ResBlock3D(nn.Module):\n    \"\"\"\n    Резидуальный блок: три свёртки с InstanceNorm и LeakyReLU.\n    \"\"\"\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3, negative_slope: float = 0.01):\n        super().__init__()\n        pad = (kernel_size - 1) // 2\n        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, padding=pad, bias=False)\n        self.in1 = nn.InstanceNorm3d(out_channels, affine=True)\n        self.act1 = nn.LeakyReLU(negative_slope=negative_slope, inplace=True)\n\n        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=kernel_size, padding=pad, bias=False)\n        self.in2 = nn.InstanceNorm3d(out_channels, affine=True)\n        self.act2 = nn.LeakyReLU(negative_slope=negative_slope, inplace=True)\n\n        self.conv3 = nn.Conv3d(out_channels, out_channels, kernel_size=kernel_size, padding=pad, bias=False)\n        self.in3 = nn.InstanceNorm3d(out_channels, affine=True)\n\n        self.skip_proj = None\n        if in_channels != out_channels:\n            self.skip_proj = nn.Conv3d(in_channels, out_channels, kernel_size=1, bias=False)\n            nn.init.kaiming_normal_(self.skip_proj.weight, nonlinearity=\"linear\")\n\n        self.final_act = nn.LeakyReLU(negative_slope=negative_slope, inplace=True)\n        for m in (self.conv1, self.conv2, self.conv3):\n            nn.init.kaiming_normal_(m.weight, nonlinearity=\"leaky_relu\")\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        identity = x\n        out = self.conv1(x); out = self.in1(out); out = self.act1(out)\n        out = self.conv2(out); out = self.in2(out); out = self.act2(out)\n        out = self.conv3(out); out = self.in3(out)\n        if self.skip_proj is not None:\n            identity = self.skip_proj(identity)\n        out = out + identity\n        return self.final_act(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:20.728540Z","iopub.execute_input":"2025-11-05T17:52:20.728807Z","iopub.status.idle":"2025-11-05T17:52:20.736663Z","shell.execute_reply.started":"2025-11-05T17:52:20.728784Z","shell.execute_reply":"2025-11-05T17:52:20.735995Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class AttentionUNetDecoderRes(nn.Module):\n    \"\"\"\n    Декодер с attention skip и residual блоками.\n    \"\"\"\n    def __init__(self,\n                 encoder_channels: List[int],\n                 decoder_channels: List[int],\n                 reduction_ratio: int = 4,\n                 use_deconv: bool = False,\n                 use_masca: bool = True,\n                 masca_N_list: Tuple[int, ...] = (7, 11),\n                 masca_on_shallow: bool = False):\n        super().__init__()\n        assert len(encoder_channels) == len(decoder_channels)\n        self.n_stages = len(encoder_channels)\n        self.use_deconv = use_deconv\n        self.masca_on_shallow = masca_on_shallow\n\n        self.deep_proj = nn.Conv3d(encoder_channels[-1], decoder_channels[0], kernel_size=1, bias=False)\n        self.deep_bn = nn.BatchNorm3d(decoder_channels[0])\n        self.deep_act = nn.ReLU(inplace=True)\n\n        self.attn_skips = nn.ModuleList()\n        for i in range(self.n_stages - 1):\n            enc_idx = self.n_stages - 2 - i\n            c_enc = encoder_channels[enc_idx]\n            c_dec = decoder_channels[i + 1]\n            self.attn_skips.append(\n                AttentionSkipBlock(in_channels=c_enc, out_channels=c_dec,\n                                   reduction_ratio=reduction_ratio)\n            )\n\n        if use_masca:\n            self.masca = MASCA3D(decoder_channels[-1], N_list=masca_N_list)\n        else:\n            self.masca = None\n\n        self.upsamplers = nn.ModuleList()\n        for i in range(self.n_stages - 1):\n            ch = decoder_channels[i]\n            # в оригинале могли быть ConvTranspose3d; для подсчёта параметров можно оставить Identity\n            self.upsamplers.append(nn.Identity())\n\n        self.decode_resblocks = nn.ModuleList()\n        for i in range(self.n_stages - 1):\n            in_ch = decoder_channels[i] + decoder_channels[i + 1]\n            out_ch = decoder_channels[i + 1]\n            self.decode_resblocks.append(ResBlock3D(in_ch, out_ch))\n\n    def forward(self, feats: List[torch.Tensor]) -> torch.Tensor:\n        assert len(feats) == self.n_stages, f\"Ожидал {self.n_stages} фич, получил {len(feats)}\"\n        x = feats[-1]\n        x = self.deep_proj(x); x = self.deep_bn(x); x = self.deep_act(x)\n\n        for i in range(self.n_stages - 1):\n            skip = feats[self.n_stages - 2 - i]\n            if isinstance(self.upsamplers[i], nn.ConvTranspose3d):\n                x = self.upsamplers[i](x)\n            else:\n                target_size = skip.shape[2:]\n                x = F.interpolate(x, size=target_size, mode='nearest')\n            skip_proj = self.attn_skips[i](skip)\n            if (self.masca is not None) and (i == self.n_stages - 2):\n                skip_proj = self.masca(skip_proj)\n            if x.shape[2:] != skip_proj.shape[2:]:\n                skip_proj = F.interpolate(skip_proj, size=x.shape[2:], mode='trilinear', align_corners=False)\n            x = torch.cat([x, skip_proj], dim=1)\n            x = self.decode_resblocks[i](x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:20.934603Z","iopub.execute_input":"2025-11-05T17:52:20.934860Z","iopub.status.idle":"2025-11-05T17:52:20.946229Z","shell.execute_reply.started":"2025-11-05T17:52:20.934841Z","shell.execute_reply":"2025-11-05T17:52:20.945456Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class AttentionFaultFormerNet(nn.Module):\n\n    def __init__(self, encoder_callable, num_classes: int = 1, use_deconv: bool = False, final_sigmoid: bool = True):\n        super().__init__()\n        # encoder_callable может быть nn.Module или любой callable, возвращающий list[Tensor]\n        self.encoder = encoder_callable\n        self.num_classes = num_classes\n        self.use_deconv = use_deconv\n        self.final_sigmoid = final_sigmoid\n        self.decoder = None\n        self.final_resblock = None\n        self.final_conv = None\n\n    def _lazy_init(self, feats: List[torch.Tensor]):\n        enc_ch = [f.shape[1] for f in feats]\n        dec_ch = enc_ch[::-1]\n        self.decoder = AttentionUNetDecoderRes(encoder_channels=enc_ch, decoder_channels=dec_ch, use_deconv=self.use_deconv)\n        self.final_resblock = ResBlock3D(dec_ch[-1], dec_ch[-1])\n        self.final_conv = nn.Conv3d(dec_ch[-1], self.num_classes, kernel_size=1, bias=True)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        feats = self.encoder(x)\n        if self.decoder is None:\n            self._lazy_init(feats)\n        dec = self.decoder(feats)\n        out = self.final_resblock(dec)\n        logits = self.final_conv(out)\n        if self.final_sigmoid:\n            logits = torch.sigmoid(logits)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:25.483054Z","iopub.execute_input":"2025-11-05T17:52:25.483337Z","iopub.status.idle":"2025-11-05T17:52:25.490646Z","shell.execute_reply.started":"2025-11-05T17:52:25.483317Z","shell.execute_reply":"2025-11-05T17:52:25.489751Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"encoder = AttentionFaultFormerEncoder(in_chans=1, embed_dim=48, use_checkpoint=False)\nmodel = AttentionFaultFormerNet(encoder_callable=encoder, num_classes=1, use_deconv=False, final_sigmoid=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T17:52:32.071265Z","iopub.execute_input":"2025-11-05T17:52:32.071724Z","iopub.status.idle":"2025-11-05T17:52:32.140571Z","shell.execute_reply.started":"2025-11-05T17:52:32.071701Z","shell.execute_reply":"2025-11-05T17:52:32.139898Z"}},"outputs":[],"execution_count":22}]}