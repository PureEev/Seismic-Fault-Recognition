{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f9364e306664b3292f4f265acf1dc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_562bff6f9de340b89040d0dae3d483f8",
              "IPY_MODEL_598d6fed89804f3b9474b2fa1261ba2a",
              "IPY_MODEL_f5a708757c7a43b19e6f653ca5a02839"
            ],
            "layout": "IPY_MODEL_d31170e4b2ca449590ce4d7a4cde09cf"
          }
        },
        "562bff6f9de340b89040d0dae3d483f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4bb191b04dc4e51b4f6ee673eaa616c",
            "placeholder": "​",
            "style": "IPY_MODEL_f521e1d622af4837887446e992d3fafe",
            "value": "Train E1:   0%"
          }
        },
        "598d6fed89804f3b9474b2fa1261ba2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59520e7292c34009a63384a325050882",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50b58a9a2fb54376aabe227dfb4c3f30",
            "value": 0
          }
        },
        "f5a708757c7a43b19e6f653ca5a02839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c805d808e4046c2a390a8f65f86812c",
            "placeholder": "​",
            "style": "IPY_MODEL_b41867b67c86496fa6a71930a154adba",
            "value": " 0/1596 [00:00&lt;?, ?it/s]"
          }
        },
        "d31170e4b2ca449590ce4d7a4cde09cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bb191b04dc4e51b4f6ee673eaa616c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f521e1d622af4837887446e992d3fafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59520e7292c34009a63384a325050882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b58a9a2fb54376aabe227dfb4c3f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c805d808e4046c2a390a8f65f86812c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b41867b67c86496fa6a71930a154adba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6iSgI2B1_lr",
        "outputId": "a3df5571-dd39-44df-d361-90bec7091fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.3)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.5.1\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import requests\n",
        "from typing import Dict, Optional\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "    _has_tqdm = True\n",
        "except ImportError:\n",
        "    _has_tqdm = False\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "# или попробовать:\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import average_precision_score, f1_score, jaccard_score\n",
        "import warnings\n",
        "import os\n",
        "import random\n",
        "import inspect\n",
        "from typing import List, Tuple, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "import monai\n",
        "from monai.networks.nets import SwinUNETR\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from scipy import ndimage as ndi"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:16.935011Z",
          "iopub.execute_input": "2025-11-19T20:24:16.935816Z",
          "iopub.status.idle": "2025-11-19T20:24:31.978219Z",
          "shell.execute_reply.started": "2025-11-19T20:24:16.935782Z",
          "shell.execute_reply": "2025-11-19T20:24:31.977575Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzpzMBxj1_lt",
        "outputId": "84823ea0-d7ea-452d-e7a4-9ac3338e90f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import gdown\n",
        "import numpy as np\n",
        "\n",
        "def download_and_unpack_gdrive_gdown(url_or_id, dest_folder='.', out_filename=None,\n",
        "                                     save_npy=False, quiet=False):\n",
        "    \"\"\"\n",
        "    Скачивает файл с Google Drive через gdown и распаковывает\n",
        "    \"\"\"\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    # если передали только id — соберём URL\n",
        "    if re.fullmatch(r\"[A-Za-z0-9_-]{10,}\", url_or_id):\n",
        "        url = f\"https://drive.google.com/uc?id={url_or_id}\"\n",
        "    else:\n",
        "        url = url_or_id\n",
        "\n",
        "    # имя выходного файла\n",
        "    if out_filename is None:\n",
        "        # попытка взять имя из URL, иначе дать дефолт\n",
        "        if \"id=\" in url:\n",
        "            out_filename = f\"downloaded_{url.split('id=')[-1]}.bin\"\n",
        "        else:\n",
        "            out_filename = os.path.basename(url) or \"downloaded_file.bin\"\n",
        "\n",
        "    out_path = os.path.join(dest_folder, out_filename)\n",
        "\n",
        "    # Скачиваем\n",
        "    if not os.path.exists(out_path):\n",
        "        gdown.download(url, out_path, quiet=quiet)"
      ],
      "metadata": {
        "trusted": true,
        "id": "25FfyNK41_lv"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1VmU4q1ySfRlrRcIawWBmqXPJ-fcAMnxO\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "download_and_unpack_gdrive_gdown(url_or_id=url,\n",
        "                                           dest_folder=\"/kaggle/working\",\n",
        "                                           out_filename=\"checkpoint.pth\",\n",
        "                                           quiet=False)\n",
        "\n",
        "file_id = \"1NOUwAFtU_1KIlf8mQtB5xwSY-3NtYnDw\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "download_and_unpack_gdrive_gdown(url_or_id=url,\n",
        "                                           dest_folder=\"/kaggle/working\",\n",
        "                                           out_filename=\"seis_train.npz\",\n",
        "                                           quiet=False)\n",
        "\n",
        "out_path = os.path.join(\"/kaggle/working\", \"seis_train.npz\")\n",
        "\n",
        "file_id = \"1QHE1gn7B8Zt99Cw1KDwyfNv6wqhM5h49\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "fault_val = download_and_unpack_gdrive_gdown(url_or_id=url,\n",
        "                                           dest_folder=\"/kaggle/working\",\n",
        "                                           out_filename=\"fault_train.npz\",\n",
        "                                           quiet=False)\n",
        "file_id = \"1vVOkYAZkq08CtWosLd27Py4quvAaTjOa\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "fault_val = download_and_unpack_gdrive_gdown(url_or_id=url,\n",
        "                                           dest_folder=\"/kaggle/working\",\n",
        "                                           out_filename=\"seis_val.npz\",\n",
        "                                           quiet=False)\n",
        "file_id = \"1YIeB6J69RUozpKwWa84m8ZXgpaQMWmP7\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "fault_val = download_and_unpack_gdrive_gdown(url_or_id=url,\n",
        "                                           dest_folder=\"/kaggle/working\",\n",
        "                                           out_filename=\"fault_val.npz\",\n",
        "                                           quiet=False)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTifsIT11_lw",
        "outputId": "8d3ecc41-aff3-4d14-8f4b-161fcf3000d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1VmU4q1ySfRlrRcIawWBmqXPJ-fcAMnxO\n",
            "From (redirected): https://drive.google.com/uc?id=1VmU4q1ySfRlrRcIawWBmqXPJ-fcAMnxO&confirm=t&uuid=dfc9d4bf-8a19-4aed-8b9f-2376550c4cf6\n",
            "To: /kaggle/working/checkpoint.pth\n",
            "100%|██████████| 731M/731M [00:12<00:00, 58.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1NOUwAFtU_1KIlf8mQtB5xwSY-3NtYnDw\n",
            "From (redirected): https://drive.google.com/uc?id=1NOUwAFtU_1KIlf8mQtB5xwSY-3NtYnDw&confirm=t&uuid=82e64845-accc-4729-b57c-c97bdf5fecbd\n",
            "To: /kaggle/working/seis_train.npz\n",
            "100%|██████████| 7.72G/7.72G [01:41<00:00, 76.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1QHE1gn7B8Zt99Cw1KDwyfNv6wqhM5h49\n",
            "From (redirected): https://drive.google.com/uc?id=1QHE1gn7B8Zt99Cw1KDwyfNv6wqhM5h49&confirm=t&uuid=0c34fff1-c73f-48be-9662-043da76b7cff\n",
            "To: /kaggle/working/fault_train.npz\n",
            "100%|██████████| 18.4M/18.4M [00:00<00:00, 53.8MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1vVOkYAZkq08CtWosLd27Py4quvAaTjOa\n",
            "From (redirected): https://drive.google.com/uc?id=1vVOkYAZkq08CtWosLd27Py4quvAaTjOa&confirm=t&uuid=1d0126e1-5219-4d91-ae8f-0c60b0c89ba4\n",
            "To: /kaggle/working/seis_val.npz\n",
            "100%|██████████| 1.42G/1.42G [00:14<00:00, 98.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YIeB6J69RUozpKwWa84m8ZXgpaQMWmP7\n",
            "From (redirected): https://drive.google.com/uc?id=1YIeB6J69RUozpKwWa84m8ZXgpaQMWmP7&confirm=t&uuid=881d0af1-1022-4754-bf49-2748c2557e68\n",
            "To: /kaggle/working/fault_val.npz\n",
            "100%|██████████| 3.36M/3.36M [00:00<00:00, 22.0MB/s]\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, Sequence, Tuple, Optional, Dict, Iterable\n",
        "import random\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SeisFaultDataset:\n",
        "    \"\"\"\n",
        "    Датасет для пар (сейсмика, fault) в виде 3D numpy-массивов.\n",
        "\n",
        "    Поддерживаемые источники:\n",
        "    - путь к .npz файлу (будет открыт через np.load(..., mmap_mode='r'))\n",
        "    - dict-like mapping имя -> np.ndarray\n",
        "\n",
        "    Парирование:\n",
        "    - если pairs не переданы, автоматически берётся отсортированное пересечение ключей\n",
        "      между seismic и fault источниками. Если пересечение пусто — бросается исключение.\n",
        "\n",
        "    Основные опции:\n",
        "    - target_shape: размер кропа (z,y,x)\n",
        "    - random_crop: True — случайные кропы, False — кропы с нулевого/центрального начала\n",
        "    - seed: для детерминированности\n",
        "    - normalize_seis: применять z-score нормализацию к сейсмике\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        seis_source: Union[str, Dict[str, np.ndarray]],\n",
        "        fault_source: Union[str, Dict[str, np.ndarray]],\n",
        "        pairs: Optional[Sequence[Tuple[str, str]]] = None,\n",
        "        target_shape: Tuple[int, int, int] = (128, 128, 128),\n",
        "        random_crop: bool = True,\n",
        "        seed: Optional[int] = None,\n",
        "        normalize_seis: bool = True,\n",
        "    ):\n",
        "        # параметры\n",
        "        self.target_shape = tuple(int(x) for x in target_shape)\n",
        "        if len(self.target_shape) != 3:\n",
        "            raise ValueError(\"target_shape должен быть кортежем длины 3\")\n",
        "        self.random_crop = bool(random_crop)\n",
        "        self.normalize_seis = bool(normalize_seis)\n",
        "        self._rng = random.Random(seed)\n",
        "\n",
        "        # загрузка источников (path -> npz mmap или оставляем dict)\n",
        "        self._seis_npz = None\n",
        "        self._fault_npz = None\n",
        "\n",
        "        if isinstance(seis_source, str):\n",
        "            if not os.path.exists(seis_source):\n",
        "                raise FileNotFoundError(seis_source)\n",
        "            self._seis_npz = np.load(seis_source, mmap_mode='r')\n",
        "            seis_source = self._seis_npz\n",
        "\n",
        "        if isinstance(fault_source, str):\n",
        "            if not os.path.exists(fault_source):\n",
        "                raise FileNotFoundError(fault_source)\n",
        "            self._fault_npz = np.load(fault_source, mmap_mode='r')\n",
        "            fault_source = self._fault_npz\n",
        "\n",
        "        # ожидаем mapping name->ndarray\n",
        "        self.seis_source = seis_source\n",
        "        self.fault_source = fault_source\n",
        "\n",
        "        # парами: либо явно, либо пересечение ключей\n",
        "        if pairs is not None:\n",
        "            self.pairs = list(pairs)\n",
        "        else:\n",
        "            seis_keys = self._keys_from_source(self.seis_source)\n",
        "            fault_keys = self._keys_from_source(self.fault_source)\n",
        "\n",
        "            # пары (имя, имя)\n",
        "            self.pairs = [(seis, fault) for seis, fault in zip(seis_keys, fault_keys)]\n",
        "\n",
        "        if len(self.pairs) == 0:\n",
        "            raise ValueError(\"No pairs available\")\n",
        "\n",
        "    # ---- Вспомогательные методы ----\n",
        "\n",
        "    def _keys_from_source(self, src):\n",
        "        \"\"\"Возвращает список ключей для mapping-источника или .files для npz.\"\"\"\n",
        "        if hasattr(src, 'files'):\n",
        "            return list(src.files)\n",
        "        if isinstance(src, dict):\n",
        "            return list(src.keys())\n",
        "        # obj, у которого можно взять ключи через итерацию\n",
        "        try:\n",
        "            return list(src.keys())\n",
        "        except Exception:\n",
        "            raise ValueError(f\"Unsupported source type: {type(src)}\")\n",
        "\n",
        "    def _get_array(self, src, key):\n",
        "        \"\"\"Простая загрузка массива; ожидаем numpy.ndarray 3D.\"\"\"\n",
        "        arr = src[key]\n",
        "        if not isinstance(arr, np.ndarray):\n",
        "            # попытка конвертации (обычно не нужна)\n",
        "            arr = np.asarray(arr)\n",
        "        if arr.ndim != 3:\n",
        "            raise ValueError(f\"Ключ {key}: ожидается 3D массив, получено {arr.ndim}D\")\n",
        "        return arr\n",
        "\n",
        "    def _compute_crop_start(self, shape: Tuple[int, int, int]) -> Tuple[int, int, int]:\n",
        "        \"\"\"Вычислить стартовые индексы для кропа (случайно или ноль/центр).\"\"\"\n",
        "        starts = []\n",
        "        for i in range(3):\n",
        "            max_start = shape[i] - self.target_shape[i]\n",
        "            if max_start <= 0:\n",
        "                starts.append(0)\n",
        "            else:\n",
        "                if self.random_crop:\n",
        "                    starts.append(self._rng.randint(0, max_start))\n",
        "                else:\n",
        "                    # по умолчанию — центрированный кроп если есть запас\n",
        "                    starts.append(max_start // 2)\n",
        "        return tuple(starts)\n",
        "\n",
        "    def _zscore_normalize(self, vol: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Z-score нормализация (для сейсмики).\"\"\"\n",
        "        v = vol.astype(np.float32, copy=False)\n",
        "        mu = v.mean()\n",
        "        sigma = v.std()\n",
        "        eps = 1e-8\n",
        "        return (v - mu) / (sigma + eps)\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        \"\"\"Вернёт (seis_crop, fault_crop, meta).\"\"\"\n",
        "        if idx < 0:\n",
        "            idx = len(self) + idx\n",
        "        seis_key, fault_key = self.pairs[idx]\n",
        "\n",
        "        seis = self._get_array(self.seis_source, seis_key)\n",
        "        fault = self._get_array(self.fault_source, fault_key)\n",
        "\n",
        "        # берем кроп по форме seismic-а\n",
        "        starts = self._compute_crop_start(seis.shape)\n",
        "        slices = tuple(slice(st, st + ts) for st, ts in zip(starts, self.target_shape))\n",
        "\n",
        "        seis_crop = seis[slices]\n",
        "        fault_crop = fault[slices]\n",
        "\n",
        "        if self.normalize_seis:\n",
        "            seis_crop = self._zscore_normalize(seis_crop)\n",
        "\n",
        "        meta = {\n",
        "            \"seis_key\": seis_key,\n",
        "            \"fault_key\": fault_key,\n",
        "            \"crop_start\": starts,\n",
        "            \"original_shapes\": (seis.shape, fault.shape),\n",
        "        }\n",
        "        return torch.unsqueeze(torch.Tensor(seis_crop), 0), torch.unsqueeze(torch.Tensor(fault_crop), 0), meta\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Закрыть mmap .npz если он был открыт.\"\"\"\n",
        "        if self._seis_npz is not None:\n",
        "            try:\n",
        "                self._seis_npz.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "            self._seis_npz = None\n",
        "        if self._fault_npz is not None:\n",
        "            try:\n",
        "                self._fault_npz.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "            self._fault_npz = None\n",
        "\n",
        "    def __del__(self):\n",
        "        self.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:31.979416Z",
          "iopub.execute_input": "2025-11-19T20:24:31.980102Z",
          "iopub.status.idle": "2025-11-19T20:24:31.997611Z",
          "shell.execute_reply.started": "2025-11-19T20:24:31.980080Z",
          "shell.execute_reply": "2025-11-19T20:24:31.996953Z"
        },
        "id": "MpHKgYSf1_lx"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = SeisFaultDataset(\"/kaggle/working/seis_train.npz\", \"/kaggle/working/fault_train.npz\",\n",
        "                      target_shape=(128,128,128), seed=42)\n",
        "\n",
        "val_ds = SeisFaultDataset(\"/kaggle/working/seis_val.npz\", \"/kaggle/working/fault_val.npz\",\n",
        "                      target_shape=(128,128,128), seed=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:31.998289Z",
          "iopub.execute_input": "2025-11-19T20:24:31.998483Z",
          "iopub.status.idle": "2025-11-19T20:24:32.032071Z",
          "shell.execute_reply.started": "2025-11-19T20:24:31.998467Z",
          "shell.execute_reply": "2025-11-19T20:24:32.031409Z"
        },
        "id": "YGJp9Qbp1_lz"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import gdown\n",
        "import numpy as np\n",
        "\n",
        "def download_and_unpack_gdrive_gdown(url_or_id, dest_folder='.', out_filename=None,\n",
        "                                     save_npy=False, quiet=False):\n",
        "    \"\"\"\n",
        "    Скачивает файл с Google Drive через gdown и распаковывает:\n",
        "      - если .npz -> загружает и (по умолчанию) сохраняет каждый массив как .npy\n",
        "      - если .zip -> распаковывает архив в dest_folder\n",
        "      - иначе пытается определить тип и вернуть путь к скачанному файлу\n",
        "\n",
        "    Аргументы:\n",
        "      url_or_id: полный URL Google Drive или только file_id\n",
        "      dest_folder: папка для сохранения/распаковки\n",
        "      out_filename: имя сохраняемого файла (опционально)\n",
        "      save_npy: сохранять ли отдельные .npy файлы при распаковке .npz\n",
        "      quiet: флаг для gdown.download (False -> подробный вывод)\n",
        "    Возвращает:\n",
        "      dict с загруженными массивами (для .npz) или информацию о распаковке (для .zip)\n",
        "    \"\"\"\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    # если передали только id — соберём URL\n",
        "    if re.fullmatch(r\"[A-Za-z0-9_-]{10,}\", url_or_id):\n",
        "        url = f\"https://drive.google.com/uc?id={url_or_id}\"\n",
        "    else:\n",
        "        url = url_or_id\n",
        "\n",
        "    # имя выходного файла\n",
        "    if out_filename is None:\n",
        "        # попытка взять имя из URL, иначе дать дефолт\n",
        "        if \"id=\" in url:\n",
        "            out_filename = f\"downloaded_{url.split('id=')[-1]}.bin\"\n",
        "        else:\n",
        "            out_filename = os.path.basename(url) or \"downloaded_file.bin\"\n",
        "\n",
        "    out_path = os.path.join(dest_folder, out_filename)\n",
        "\n",
        "    # Скачиваем\n",
        "    if not os.path.exists(out_path):\n",
        "        gdown.download(url, out_path, quiet=quiet)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qD-BazDx1_l0"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_id = \"1gt1ig-To2DcbKmvFQL9UCKW8zMvgJy9f\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "download_and_unpack_gdrive_gdown(url_or_id=url,\n",
        "                                           dest_folder=\"/kaggle/working\",\n",
        "                                           out_filename=\"client_secret.json\",\n",
        "                                           quiet=False)\n",
        "\n",
        "out_path = os.path.join(\"/content\", \"client_secret.json\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "sNIhaXq01_l1"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_id = \"1ksI9_TpSJ8tAZp88MFV3j4z-paDuaJbY\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "download_and_unpack_gdrive_gdown(url_or_id=url,\n",
        "                                           dest_folder=\"/kaggle/working\",\n",
        "                                           out_filename=\"token.json\",\n",
        "                                           quiet=False)\n",
        "\n",
        "out_path = os.path.join(\"/content\", \"token.json\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "yG38RTuA1_l1"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from googleapiclient.discovery import build\n",
        "    from googleapiclient.http import MediaFileUpload\n",
        "    from google.auth.transport.requests import Request\n",
        "    from googleapiclient.errors import HttpError\n",
        "except Exception:\n",
        "    # в ноутбуке команда с !pip обычно работает — оставляем как есть\n",
        "    try:\n",
        "        print(\"[gdrive] google libs not found — attempting to install (may take a moment)...\")\n",
        "        get_ipython()  # if in notebook\n",
        "        !pip install --quiet google-api-python-client google-auth google-auth-oauthlib\n",
        "        from googleapiclient.discovery import build\n",
        "        from googleapiclient.http import MediaFileUpload\n",
        "        from google.auth.transport.requests import Request\n",
        "        from googleapiclient.errors import HttpError\n",
        "    except Exception as e:\n",
        "        print(\"[gdrive] Failed to import google libs after install attempt:\", e)\n",
        "        # we will still define placeholders below\n",
        "\n",
        "def setup_gdrive_from_token(token_path: str, folder_name: str):\n",
        "    \"\"\"\n",
        "    token.json должен быть pickled credentials (pickle.dump(creds))\n",
        "    Возвращает (service, folder_id) или (None, None)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(token_path):\n",
        "        print(f\"[gdrive] token.json not found at {token_path}. Upload token.json to enable uploads.\")\n",
        "        return None, None\n",
        "    try:\n",
        "        with open(token_path, \"rb\") as f:\n",
        "            creds = pickle.load(f)\n",
        "    except Exception as e:\n",
        "        print(\"[gdrive] Failed to load token.json:\", e)\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        if creds and getattr(creds, \"expired\", False) and getattr(creds, \"refresh_token\", None):\n",
        "            try:\n",
        "                creds.refresh(Request())\n",
        "                with open(token_path, \"wb\") as f:\n",
        "                    pickle.dump(creds, f)\n",
        "                print(\"[gdrive] Token refreshed and saved.\")\n",
        "            except Exception as e:\n",
        "                print(\"[gdrive] Token refresh failed:\", e)\n",
        "    except Exception as e:\n",
        "        print(\"[gdrive] Token refresh attempt exception:\", e)\n",
        "\n",
        "    try:\n",
        "        service = build(\"drive\", \"v3\", credentials=creds, cache_discovery=False)\n",
        "    except Exception as e:\n",
        "        print(\"[gdrive] Failed to build Drive service:\", e)\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        q = f\"name = '{folder_name}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
        "        res = service.files().list(q=q, fields=\"files(id, name)\").execute()\n",
        "        files = res.get(\"files\", [])\n",
        "        if files:\n",
        "            folder_id = files[0][\"id\"]\n",
        "            print(f\"[gdrive] Found folder '{folder_name}' id={folder_id}\")\n",
        "        else:\n",
        "            meta = {\"name\": folder_name, \"mimeType\": \"application/vnd.google-apps.folder\"}\n",
        "            created = service.files().create(body=meta, fields=\"id\").execute()\n",
        "            folder_id = created.get(\"id\")\n",
        "            print(f\"[gdrive] Created folder '{folder_name}' id={folder_id}\")\n",
        "        print(\"Folder link: https://drive.google.com/drive/folders/\" + folder_id)\n",
        "        return service, folder_id\n",
        "    except Exception as e:\n",
        "        print(\"[gdrive] Failed to find/create folder:\", e)\n",
        "        return service, None\n",
        "\n",
        "def try_upload_file(service, folder_id, local_path):\n",
        "    if not os.path.exists(local_path):\n",
        "        print(f\"[upload] SKIP — file not found: {local_path}\")\n",
        "        return False\n",
        "    if service is None or folder_id is None:\n",
        "        print(f\"[upload] SKIP — Drive not configured (service set? {service is not None}, folder_id set? {folder_id is not None})\")\n",
        "        return False\n",
        "    try:\n",
        "        media = MediaFileUpload(local_path, resumable=True)\n",
        "        meta = {\"name\": os.path.basename(local_path), \"parents\": [folder_id]}\n",
        "        req = service.files().create(body=meta, media_body=media, fields=\"id\")\n",
        "        resp = req.execute()\n",
        "        fid = resp.get(\"id\")\n",
        "        print(f\"[upload] SUCCESS: {local_path} -> fileId={fid}\")\n",
        "        return True\n",
        "    except HttpError as e:\n",
        "        try:\n",
        "            content = e.content.decode() if hasattr(e, \"content\") else str(e)\n",
        "        except Exception:\n",
        "            content = str(e)\n",
        "        print(f\"[upload] HttpError while uploading {local_path}: {content}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"[upload] Exception while uploading {local_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Путь к client_secret.json (если вы хотите пробовать interactive flow в Kaggle)\n",
        "CLIENT_SECRETS_PATH = \"/content/client_secret.json\"  # если используете интерактивный flow\n",
        "# Путь к token.json (предпочтительно положите сюда из локальной машины после генерации)\n",
        "TOKEN_PATH = \"/content/token.json\"\n",
        "# Имя папки в вашем Google Drive куда будут загружаться файлы\n",
        "GDRIVE_FOLDER_NAME = \"kaggle_swinunetr_experiments\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:32.033602Z",
          "iopub.execute_input": "2025-11-19T20:24:32.034211Z",
          "iopub.status.idle": "2025-11-19T20:24:32.052473Z",
          "shell.execute_reply.started": "2025-11-19T20:24:32.034189Z",
          "shell.execute_reply": "2025-11-19T20:24:32.051784Z"
        },
        "id": "JCNLLQPU1_l2"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.inferers import sliding_window_inference\n",
        "\n",
        "ROI_SIZE = (128,128,128)\n",
        "OVERLAP = 0.25\n",
        "SW_BATCH_SIZE = 1\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, loss_fn, epoch, scaler, main_device, accumulation_steps=1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Train E{epoch}\")\n",
        "    device0 = main_device\n",
        "\n",
        "    for i, batch in pbar:\n",
        "        if len(batch) == 3:\n",
        "            imgs, masks, metas = batch\n",
        "        else:\n",
        "            imgs, masks = batch\n",
        "\n",
        "        # Dataset даёт (B, C, D, H, W) — не нужно добавлять оси\n",
        "        imgs = imgs.float().to(device0, non_blocking=True).contiguous()\n",
        "        masks = masks.float().to(device0, non_blocking=True).contiguous()\n",
        "\n",
        "        # защита: уверимся, что формы корректны\n",
        "        assert imgs.ndim == 5, f\"imgs must be 5D (B,C,D,H,W), got {imgs.shape}\"\n",
        "        assert masks.ndim == 5, f\"masks must be 5D (B,C,D,H,W), got {masks.shape}\"\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        #with torch.amp.autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, masks) / accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        running_loss += float(loss.item() * accumulation_steps)\n",
        "        pbar.set_postfix(loss=running_loss / (i + 1))\n",
        "\n",
        "        del outputs, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return running_loss / max(1, len(dataloader))\n",
        "\n",
        "def validate(model, dataloader, main_device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    TP = FP = FN = 0\n",
        "    predictor = unwrap_model(model)\n",
        "    device0 = main_device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Val\")\n",
        "        for i, batch in pbar:\n",
        "            if len(batch) == 3:\n",
        "                imgs, masks, metas = batch\n",
        "            else:\n",
        "                imgs, masks = batch\n",
        "\n",
        "            # не добавляем лишнюю ось\n",
        "            inputs = imgs.float().to(device0, non_blocking=True)\n",
        "            masks = masks.float().to(device0, non_blocking=True)\n",
        "\n",
        "            assert inputs.ndim == 5, f\"inputs must be 5D (B,C,D,H,W), got {inputs.shape}\"\n",
        "            assert masks.ndim == 5, f\"masks must be 5D (B,C,D,H,W), got {masks.shape}\"\n",
        "\n",
        "            logits = sliding_window_inference(\n",
        "                inputs=inputs,\n",
        "                roi_size=ROI_SIZE,\n",
        "                sw_batch_size=SW_BATCH_SIZE,\n",
        "                predictor=predictor,\n",
        "                overlap=OVERLAP\n",
        "            )\n",
        "\n",
        "            val_loss += float(loss_fn(logits, masks).item())\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs >= 0.5).float()\n",
        "\n",
        "            preds_flat = preds.view(-1)\n",
        "            masks_flat = masks.view(-1)\n",
        "\n",
        "            TP += int(((preds_flat == 1.0) & (masks_flat == 1.0)).sum().item())\n",
        "            FP += int(((preds_flat == 1.0) & (masks_flat == 0.0)).sum().item())\n",
        "            FN += int(((preds_flat == 0.0) & (masks_flat == 1.0)).sum().item())\n",
        "\n",
        "    val_loss = val_loss / max(1, len(dataloader))\n",
        "    prec = TP / (TP + FP) if (TP + FP) > 0 else float(\"nan\")\n",
        "    rec = TP / (TP + FN) if (TP + FN) > 0 else float(\"nan\")\n",
        "    denom = 2 * TP + FP + FN\n",
        "    val_f1 = 2.0 * TP / denom if denom > 0 else float(\"nan\")\n",
        "    return val_loss, val_f1, prec, rec\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:32.053230Z",
          "iopub.execute_input": "2025-11-19T20:24:32.053566Z",
          "iopub.status.idle": "2025-11-19T20:24:32.068122Z",
          "shell.execute_reply.started": "2025-11-19T20:24:32.053537Z",
          "shell.execute_reply": "2025-11-19T20:24:32.067551Z"
        },
        "id": "9Cz-_lea1_l3"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "def _strip_module_prefix(sd):\n",
        "    new = {}\n",
        "    for k, v in sd.items():\n",
        "        if k.startswith(\"module.\"):\n",
        "            new[k[len(\"module.\"):]] = v\n",
        "        else:\n",
        "            new[k] = v\n",
        "    return new\n",
        "\n",
        "def _add_module_prefix(sd):\n",
        "    return {\"module.\" + k: v for k, v in sd.items()}\n",
        "\n",
        "def _intersect_state_dicts(src_sd, target_sd):\n",
        "    \"\"\"Вернуть state_dict, содержащий только те пары из src_sd, которые есть в target_sd и совпадают по форме.\"\"\"\n",
        "    filtered = {}\n",
        "    target_items = target_sd.items()\n",
        "    target_shapes = {k: v.shape for k, v in target_items}\n",
        "    for k, v in src_sd.items():\n",
        "        if k in target_shapes and getattr(v, \"shape\", None) == target_shapes[k]:\n",
        "            filtered[k] = v\n",
        "    return filtered\n",
        "\n",
        "def load_checkpoint(\n",
        "    ckpt_path,\n",
        "    model,\n",
        "    optimizer=None,\n",
        "    scheduler=None,\n",
        "    scaler=None,\n",
        "    device=torch.device(\"cpu\"),\n",
        "    load_optimizer=True,\n",
        "    load_scheduler=True,\n",
        "    load_scaler=True,\n",
        "    strict=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Загружает чекпойнт, делая безопасные проверки:\n",
        "      - корректно обрабатывает module. префикс и DataParallel\n",
        "      - при strict=False пытается частично загрузить пересекающиеся слои\n",
        "      - аккуратно обрабатывает ошибки optimizer/scheduler/scaler (не падает)\n",
        "    Возвращает: (ckpt_dict, next_epoch, metrics, info)\n",
        "      - info содержит diagnostic поля: missing_keys, unexpected_keys, loaded_params_count и др.\n",
        "    \"\"\"\n",
        "    assert os.path.exists(ckpt_path), f\"Checkpoint not found: {ckpt_path}\"\n",
        "    # безопасный map_location\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "    # model_state может называться по-разному\n",
        "    model_state = ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\", None))\n",
        "    if model_state is None:\n",
        "        raise RuntimeError(\"Checkpoint does not contain 'model_state_dict' or 'state_dict'\")\n",
        "\n",
        "    # unwrap модель если DataParallel -> работаем с model.module\n",
        "    is_dp_model = isinstance(model, torch.nn.DataParallel)\n",
        "    model_to_load = model.module if is_dp_model else model\n",
        "    target_sd = model_to_load.state_dict()\n",
        "\n",
        "    info = {\"missing_keys\": [], \"unexpected_keys\": [], \"loaded_param_count\": 0, \"notes\": []}\n",
        "\n",
        "    # Попробуем разные варианты (префикс/без префикса)\n",
        "    src_sd = model_state\n",
        "    # если ключи объекта — не tensor'ы (редко), предполагаем что это корректный dict\n",
        "    # Проверим префиксы\n",
        "    src_keys_sample = list(src_sd.keys())[:5]\n",
        "    target_keys_sample = list(target_sd.keys())[:5]\n",
        "\n",
        "    # Если src имеет module. а target нет -> снять префикс\n",
        "    if any(k.startswith(\"module.\") for k in src_sd.keys()) and not any(k.startswith(\"module.\") for k in target_sd.keys()):\n",
        "        src_sd = _strip_module_prefix(src_sd)\n",
        "        info[\"notes\"].append(\"Stripped 'module.' prefix from checkpoint keys.\")\n",
        "    # Если src не имеет module. а target ожидает module. -> добавить префикс\n",
        "    elif not any(k.startswith(\"module.\") for k in src_sd.keys()) and any(k.startswith(\"module.\") for k in target_sd.keys()):\n",
        "        src_sd = _add_module_prefix(src_sd)\n",
        "        info[\"notes\"].append(\"Added 'module.' prefix to checkpoint keys to match DataParallel model.\")\n",
        "\n",
        "    # Попытка загрузки штатно\n",
        "    try:\n",
        "        res = model_to_load.load_state_dict(src_sd, strict=strict)\n",
        "        # res is NamedTuple(missing_keys, unexpected_keys) when strict=False (or empty if strict=True and succeeded)\n",
        "        missing = getattr(res, \"missing_keys\", []) or []\n",
        "        unexpected = getattr(res, \"unexpected_keys\", []) or []\n",
        "        info[\"missing_keys\"] = missing\n",
        "        info[\"unexpected_keys\"] = unexpected\n",
        "        info[\"loaded_param_count\"] = sum(1 for k in src_sd.keys() if k in target_sd and src_sd[k].shape == target_sd[k].shape)\n",
        "        print(f\"[load] Model weights loaded (strict={strict}). Missing: {len(missing)}, Unexpected: {len(unexpected)}.\")\n",
        "    except RuntimeError as e:\n",
        "        # Если strict=True — будем пробовать частичную загрузку при возможности\n",
        "        print(\"[load] load_state_dict failed:\", e)\n",
        "        if strict:\n",
        "            print(\"[load] strict=True и загрузка провалилась. Попробуйте вызвать с strict=False или отладить mismatch ключей.\")\n",
        "            raise\n",
        "        else:\n",
        "            # Попытка частичной загрузки: взять пересекающиеся параметры по имени и форме\n",
        "            filtered = _intersect_state_dicts(src_sd, target_sd)\n",
        "            if len(filtered) == 0:\n",
        "                raise RuntimeError(\"[load] Частичная загрузка невозможна: нет совпадающих параметров по имени/форме.\")\n",
        "            missing_keys = [k for k in target_sd.keys() if k not in filtered.keys()]\n",
        "            unexpected_keys = [k for k in filtered.keys() if k not in target_sd.keys()]\n",
        "            model_to_load.load_state_dict(filtered, strict=False)\n",
        "            info[\"missing_keys\"] = missing_keys\n",
        "            info[\"unexpected_keys\"] = unexpected_keys\n",
        "            info[\"loaded_param_count\"] = len(filtered)\n",
        "            info[\"notes\"].append(\"Partial load: loaded only intersecting keys (name+shape).\")\n",
        "\n",
        "    # Попробуем загрузить optimizer/scheduler/scaler если нужно (и если они есть в чекпойнте)\n",
        "    if optimizer is not None and load_optimizer:\n",
        "        opt_state = ckpt.get(\"optimizer_state_dict\", None)\n",
        "        if opt_state is not None:\n",
        "            try:\n",
        "                optimizer.load_state_dict(opt_state)\n",
        "                print(\"[load] Optimizer state loaded.\")\n",
        "            except Exception as e:\n",
        "                print(\"[load] Не удалось загрузить optimizer state:\", e)\n",
        "                info[\"notes\"].append(\"Optimizer load failed; keep current optimizer state. To avoid, create optimizer with same param groups or set load_optimizer=False.\")\n",
        "    if scheduler is not None and load_scheduler:\n",
        "        sch_state = ckpt.get(\"scheduler_state_dict\", None)\n",
        "        if sch_state is not None:\n",
        "            try:\n",
        "                scheduler.load_state_dict(sch_state)\n",
        "                print(\"[load] Scheduler state loaded.\")\n",
        "            except Exception as e:\n",
        "                print(\"[load] Не удалось загрузить scheduler state:\", e)\n",
        "                info[\"notes\"].append(\"Scheduler load failed; keep current scheduler state.\")\n",
        "    if scaler is not None and load_scaler:\n",
        "        # в чекпойнте иногда называется 'scaler_state_dict' или 'amp_scaler'\n",
        "        sc_state = ckpt.get(\"scaler_state_dict\", ckpt.get(\"scaler\", ckpt.get(\"amp_scaler\", None)))\n",
        "        if sc_state is not None:\n",
        "            try:\n",
        "                scaler.load_state_dict(sc_state)\n",
        "                print(\"[load] GradScaler state loaded.\")\n",
        "            except Exception as e:\n",
        "                print(\"[load] Не удалось загрузить scaler state:\", e)\n",
        "                info[\"notes\"].append(\"GradScaler load failed; keep current scaler state.\")\n",
        "\n",
        "    # вернём полезные метаданные\n",
        "    epoch = ckpt.get(\"epoch\", None)\n",
        "    next_epoch = (epoch + 1) if epoch is not None else None\n",
        "    metrics = {k: ckpt.get(k) for k in (\"val_f1\", \"val_loss\", \"val_precision\", \"val_recall\") if k in ckpt}\n",
        "\n",
        "    return ckpt, next_epoch, metrics, info\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:32.977024Z",
          "iopub.execute_input": "2025-11-19T20:24:32.977625Z",
          "iopub.status.idle": "2025-11-19T20:24:32.994386Z",
          "shell.execute_reply.started": "2025-11-19T20:24:32.977602Z",
          "shell.execute_reply": "2025-11-19T20:24:32.993507Z"
        },
        "id": "JSm6VchZ1_l4"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from typing import Dict, Any, Optional\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def _get_device(device: Optional[torch.device] = None) -> torch.device:\n",
        "    if device is None:\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if isinstance(device, str):\n",
        "        return torch.device(device)\n",
        "    return device\n",
        "\n",
        "def build_swinunetr(params: Dict[str, Any],\n",
        "                           in_ch: int = 1,\n",
        "                           out_ch: int = 1,\n",
        "                           device: Optional[torch.device] = None,\n",
        "                           wrap_dataparallel: bool = True) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Сборка SwinUNETR из словаря params:\n",
        "    - фильтрует params по сигнатуре конструктора (чтобы игнорировать лишние ключи);\n",
        "    - создаёт модель, при наличии >1 GPU оборачивает в DataParallel (если wrap_dataparallel=True);\n",
        "    - возвращает модель на указанном device.\n",
        "    \"\"\"\n",
        "    device = _get_device(device)\n",
        "    sig = inspect.signature(SwinUNETR.__init__)\n",
        "    allowed = {p for p in sig.parameters if p not in (\"self\", \"in_channels\", \"out_channels\")}\n",
        "    call_kwargs = {k: v for k, v in params.items() if k in allowed}\n",
        "    model = SwinUNETR(in_ch, out_ch, **call_kwargs)\n",
        "    if wrap_dataparallel and torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "    return model.to(device)\n",
        "\n",
        "MODEL_PARAMS = dict(\n",
        "    patch_size=(2, 2, 2),\n",
        "    depths=(2, 2, 2, 1),\n",
        "    num_heads=(3, 6, 12, 24),\n",
        "    window_size=(7, 7, 7),\n",
        "    qkv_bias=True,\n",
        "    mlp_ratio=4.0,\n",
        "    feature_size=48,\n",
        "    drop_rate=0.0,\n",
        "    attn_drop_rate=0.0,\n",
        "    dropout_path_rate=0.1,\n",
        "    patch_norm=True,\n",
        "    spatial_dims=3,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:36.988663Z",
          "iopub.execute_input": "2025-11-19T20:24:36.989226Z",
          "iopub.status.idle": "2025-11-19T20:24:36.997539Z",
          "shell.execute_reply.started": "2025-11-19T20:24:36.989203Z",
          "shell.execute_reply": "2025-11-19T20:24:36.996840Z"
        },
        "id": "V7k-K06V1_l5"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BinaryDiceLoss(nn.Module):\n",
        "    def __init__(self, smooth: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        logits: Tensor with shape (B,1,D,H,W) or (B,D,H,W)  (raw logits)\n",
        "        target: Tensor with shape (B,1,D,H,W) or (B,D,H,W)  (0/1 labels)\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        # Если target без канального измерения — добавим\n",
        "        if target.dim() == probs.dim() - 1:\n",
        "            target = target.unsqueeze(1)\n",
        "\n",
        "        # привести тип и устройство\n",
        "        target = target.to(dtype=probs.dtype, device=probs.device)\n",
        "\n",
        "        # выпрямляем по батчу\n",
        "        probs_flat = probs.view(probs.size(0), -1)\n",
        "        target_flat = target.view(target.size(0), -1)\n",
        "\n",
        "        intersection = (probs_flat * target_flat).sum(dim=1)\n",
        "        dice = (2.0 * intersection + self.smooth) / (probs_flat.sum(dim=1) + target_flat.sum(dim=1) + self.smooth)\n",
        "\n",
        "        # средняя Dice loss по батчу\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "\n",
        "class BinaryFocalLoss(nn.Module):\n",
        "    def __init__(self, gamma: float = 2.0, alpha: float = 0.25, reduction: str = 'mean', eps: float = 1e-6):\n",
        "        \"\"\"\n",
        "        alpha: weight for the positive class (class=1). Negative class weight will be (1-alpha).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        if target.dim() == probs.dim() - 1:\n",
        "            target = target.unsqueeze(1)\n",
        "\n",
        "        # привести тип/устройство\n",
        "        target = target.to(dtype=probs.dtype, device=probs.device)\n",
        "\n",
        "        # boolean маска для класса 1\n",
        "        pos_mask = target.eq(1.0)\n",
        "        neg_mask = ~pos_mask\n",
        "\n",
        "        # pt = p_t: вероятность правильного класса\n",
        "        pt = torch.where(pos_mask, probs, 1.0 - probs)\n",
        "\n",
        "        # защита от лог(0)\n",
        "        pt = pt.clamp(min=self.eps, max=1.0 - self.eps)\n",
        "\n",
        "        # альфа для каждого элемента: alpha для положительных, 1-alpha для отрицательных\n",
        "        alpha_t = torch.where(pos_mask, self.alpha, 1.0 - self.alpha)\n",
        "\n",
        "        focal_weight = (1.0 - pt) ** self.gamma\n",
        "\n",
        "        # базовый лог-лист\n",
        "        loss = - alpha_t * focal_weight * torch.log(pt)\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        else:\n",
        "            return loss  # 'none'\n",
        "\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, w_bce: float = 0.2, w_dice: float = 0.4, w_focal: float = 0.4):\n",
        "        super().__init__()\n",
        "        # BCEWithLogitsLoss принимает raw logits и target в формате float\n",
        "        self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        self.dice = BinaryDiceLoss()\n",
        "        self.focal = BinaryFocalLoss(gamma=2.0, alpha=0.25, reduction='mean')\n",
        "        self.w_bce = w_bce\n",
        "        self.w_dice = w_dice\n",
        "        self.w_focal = w_focal\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        # Приведём target по форме к logits, если нужно\n",
        "        if target.dim() == logits.dim() - 1:\n",
        "            target = target.unsqueeze(1)\n",
        "\n",
        "        # привести тип и устройство\n",
        "        target = target.to(dtype=logits.dtype, device=logits.device)\n",
        "\n",
        "        loss_bce = self.bce(logits, target)\n",
        "        loss_dice = self.dice(logits, target)\n",
        "        loss_focal = self.focal(logits, target)\n",
        "\n",
        "        return self.w_bce * loss_bce + self.w_dice * loss_dice + self.w_focal * loss_focal\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:39.637808Z",
          "iopub.execute_input": "2025-11-19T20:24:39.638553Z",
          "iopub.status.idle": "2025-11-19T20:24:39.650485Z",
          "shell.execute_reply.started": "2025-11-19T20:24:39.638525Z",
          "shell.execute_reply": "2025-11-19T20:24:39.649613Z"
        },
        "id": "m_4H09U01_l6"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gc\n",
        "# device info\n",
        "ngpu = torch.cuda.device_count()\n",
        "print(\"GPUs available:\", ngpu)\n",
        "if ngpu > 0:\n",
        "    for i in range(ngpu):\n",
        "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "USE_DATAPARALLEL = True\n",
        "MAIN_DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create encoder and model on CPU first (safer) then move/wrap\n",
        "# 2) Создаём модель и переносим на устройство\n",
        "#model = AttentionFaultFormerNet(enc, num_classes=1, final_sigmoid=False)\n",
        "model = build_swinunetr(MODEL_PARAMS, in_ch=1, out_ch=1)\n",
        "model.to(MAIN_DEVICE)\n",
        "# Move model to main device (cuda:0 if available)\n",
        "ckpt_path = \"/kaggle/working/checkpoint.pth\"\n",
        "\n",
        "\n",
        "for name, p in model.named_parameters():\n",
        "    print(\"param\", name, p.device)\n",
        "for name, b in model.named_buffers():\n",
        "    print(\"buffer\", name, b.device)\n",
        "\n",
        "# Wrap in DataParallel only if beneficial\n",
        "if USE_DATAPARALLEL and ngpu > 1:\n",
        "    device_ids = list(range(ngpu))\n",
        "    print(\"Wrapping model in nn.DataParallel on device_ids =\", device_ids)\n",
        "    model.to('cuda:0')\n",
        "    model = nn.DataParallel(model, device_ids=device_ids, output_device = 0)\n",
        "    is_dp = True\n",
        "else:\n",
        "    if USE_DATAPARALLEL and ngpu <= 1:\n",
        "        print(\"DataParallel requested but only <=1 GPU found — skipping DataParallel (use single-GPU).\")\n",
        "    is_dp = False\n",
        "\n",
        "print(\"Model device (example param):\", next(model.parameters()).device)\n",
        "print(\"Is DataParallel:\", isinstance(model, nn.DataParallel))\n",
        "\n",
        "# utility: function to unwrap for saving / scheduler etc.\n",
        "def unwrap_model(m):\n",
        "    return m.module if isinstance(m, nn.DataParallel) else m\n",
        "\n",
        "# used_params for checkpoint metadata\n",
        "used_params = dict(embed_dim=48, use_checkpoint=True)\n",
        "\n",
        "# Print parameter counts (optional)\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total params: {total/1e6:.3f} M, Trainable: {trainable/1e6:.3f} M\")\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Prepare gdrive\n",
        "# ---------------------------\n",
        "gdrive_service, gdrive_folder_id = setup_gdrive_from_token(TOKEN_PATH, GDRIVE_FOLDER_NAME)\n",
        "print(\"Drive configured?\", gdrive_service is not None, gdrive_folder_id is not None)\n",
        "\n",
        "# ---------------------------\n",
        "# Loss, optimizer, scaler, scheduler\n",
        "# ---------------------------\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = CombinedLoss()\n",
        "optimizer = optim.AdamW(unwrap_model(model).parameters(), lr=2e-3)\n",
        "scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "SCHEDULER_TYPE = \"ReduceLROnPlateau\"\n",
        "if SCHEDULER_TYPE == \"ReduceLROnPlateau\":\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=2)\n",
        "elif SCHEDULER_TYPE == \"CosineAnnealingLR\":\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "else:\n",
        "    scheduler = None\n",
        "model = model.to(MAIN_DEVICE)\n",
        "ckpt, next_epoch, metrics, info = load_checkpoint(\n",
        "    ckpt_path,\n",
        "    model=model,           # модель уже перемещена на device / возможно DataParallel обёртка\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    scaler=scaler,\n",
        "    device=MAIN_DEVICE,\n",
        "    load_optimizer=True,\n",
        "    load_scheduler=True,\n",
        "    load_scaler=True,\n",
        "    strict=False,         # настраиваем, если архитектура чуть отличается\n",
        ")\n",
        "print(info)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:42.184535Z",
          "iopub.execute_input": "2025-11-19T20:24:42.184832Z",
          "iopub.status.idle": "2025-11-19T20:24:44.063052Z",
          "shell.execute_reply.started": "2025-11-19T20:24:42.184811Z",
          "shell.execute_reply": "2025-11-19T20:24:44.062163Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLtZSK4X1_l6",
        "outputId": "a4bc346b-1cc0-4bf5-fcf7-e3b620ee956f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUs available: 0\n",
            "param swinViT.patch_embed.proj.weight cpu\n",
            "param swinViT.patch_embed.proj.bias cpu\n",
            "param swinViT.patch_embed.norm.weight cpu\n",
            "param swinViT.patch_embed.norm.bias cpu\n",
            "param swinViT.layers1.0.blocks.0.norm1.weight cpu\n",
            "param swinViT.layers1.0.blocks.0.norm1.bias cpu\n",
            "param swinViT.layers1.0.blocks.0.attn.relative_position_bias_table cpu\n",
            "param swinViT.layers1.0.blocks.0.attn.qkv.weight cpu\n",
            "param swinViT.layers1.0.blocks.0.attn.qkv.bias cpu\n",
            "param swinViT.layers1.0.blocks.0.attn.proj.weight cpu\n",
            "param swinViT.layers1.0.blocks.0.attn.proj.bias cpu\n",
            "param swinViT.layers1.0.blocks.0.norm2.weight cpu\n",
            "param swinViT.layers1.0.blocks.0.norm2.bias cpu\n",
            "param swinViT.layers1.0.blocks.0.mlp.linear1.weight cpu\n",
            "param swinViT.layers1.0.blocks.0.mlp.linear1.bias cpu\n",
            "param swinViT.layers1.0.blocks.0.mlp.linear2.weight cpu\n",
            "param swinViT.layers1.0.blocks.0.mlp.linear2.bias cpu\n",
            "param swinViT.layers1.0.blocks.1.norm1.weight cpu\n",
            "param swinViT.layers1.0.blocks.1.norm1.bias cpu\n",
            "param swinViT.layers1.0.blocks.1.attn.relative_position_bias_table cpu\n",
            "param swinViT.layers1.0.blocks.1.attn.qkv.weight cpu\n",
            "param swinViT.layers1.0.blocks.1.attn.qkv.bias cpu\n",
            "param swinViT.layers1.0.blocks.1.attn.proj.weight cpu\n",
            "param swinViT.layers1.0.blocks.1.attn.proj.bias cpu\n",
            "param swinViT.layers1.0.blocks.1.norm2.weight cpu\n",
            "param swinViT.layers1.0.blocks.1.norm2.bias cpu\n",
            "param swinViT.layers1.0.blocks.1.mlp.linear1.weight cpu\n",
            "param swinViT.layers1.0.blocks.1.mlp.linear1.bias cpu\n",
            "param swinViT.layers1.0.blocks.1.mlp.linear2.weight cpu\n",
            "param swinViT.layers1.0.blocks.1.mlp.linear2.bias cpu\n",
            "param swinViT.layers1.0.downsample.reduction.weight cpu\n",
            "param swinViT.layers1.0.downsample.norm.weight cpu\n",
            "param swinViT.layers1.0.downsample.norm.bias cpu\n",
            "param swinViT.layers2.0.blocks.0.norm1.weight cpu\n",
            "param swinViT.layers2.0.blocks.0.norm1.bias cpu\n",
            "param swinViT.layers2.0.blocks.0.attn.relative_position_bias_table cpu\n",
            "param swinViT.layers2.0.blocks.0.attn.qkv.weight cpu\n",
            "param swinViT.layers2.0.blocks.0.attn.qkv.bias cpu\n",
            "param swinViT.layers2.0.blocks.0.attn.proj.weight cpu\n",
            "param swinViT.layers2.0.blocks.0.attn.proj.bias cpu\n",
            "param swinViT.layers2.0.blocks.0.norm2.weight cpu\n",
            "param swinViT.layers2.0.blocks.0.norm2.bias cpu\n",
            "param swinViT.layers2.0.blocks.0.mlp.linear1.weight cpu\n",
            "param swinViT.layers2.0.blocks.0.mlp.linear1.bias cpu\n",
            "param swinViT.layers2.0.blocks.0.mlp.linear2.weight cpu\n",
            "param swinViT.layers2.0.blocks.0.mlp.linear2.bias cpu\n",
            "param swinViT.layers2.0.blocks.1.norm1.weight cpu\n",
            "param swinViT.layers2.0.blocks.1.norm1.bias cpu\n",
            "param swinViT.layers2.0.blocks.1.attn.relative_position_bias_table cpu\n",
            "param swinViT.layers2.0.blocks.1.attn.qkv.weight cpu\n",
            "param swinViT.layers2.0.blocks.1.attn.qkv.bias cpu\n",
            "param swinViT.layers2.0.blocks.1.attn.proj.weight cpu\n",
            "param swinViT.layers2.0.blocks.1.attn.proj.bias cpu\n",
            "param swinViT.layers2.0.blocks.1.norm2.weight cpu\n",
            "param swinViT.layers2.0.blocks.1.norm2.bias cpu\n",
            "param swinViT.layers2.0.blocks.1.mlp.linear1.weight cpu\n",
            "param swinViT.layers2.0.blocks.1.mlp.linear1.bias cpu\n",
            "param swinViT.layers2.0.blocks.1.mlp.linear2.weight cpu\n",
            "param swinViT.layers2.0.blocks.1.mlp.linear2.bias cpu\n",
            "param swinViT.layers2.0.downsample.reduction.weight cpu\n",
            "param swinViT.layers2.0.downsample.norm.weight cpu\n",
            "param swinViT.layers2.0.downsample.norm.bias cpu\n",
            "param swinViT.layers3.0.blocks.0.norm1.weight cpu\n",
            "param swinViT.layers3.0.blocks.0.norm1.bias cpu\n",
            "param swinViT.layers3.0.blocks.0.attn.relative_position_bias_table cpu\n",
            "param swinViT.layers3.0.blocks.0.attn.qkv.weight cpu\n",
            "param swinViT.layers3.0.blocks.0.attn.qkv.bias cpu\n",
            "param swinViT.layers3.0.blocks.0.attn.proj.weight cpu\n",
            "param swinViT.layers3.0.blocks.0.attn.proj.bias cpu\n",
            "param swinViT.layers3.0.blocks.0.norm2.weight cpu\n",
            "param swinViT.layers3.0.blocks.0.norm2.bias cpu\n",
            "param swinViT.layers3.0.blocks.0.mlp.linear1.weight cpu\n",
            "param swinViT.layers3.0.blocks.0.mlp.linear1.bias cpu\n",
            "param swinViT.layers3.0.blocks.0.mlp.linear2.weight cpu\n",
            "param swinViT.layers3.0.blocks.0.mlp.linear2.bias cpu\n",
            "param swinViT.layers3.0.blocks.1.norm1.weight cpu\n",
            "param swinViT.layers3.0.blocks.1.norm1.bias cpu\n",
            "param swinViT.layers3.0.blocks.1.attn.relative_position_bias_table cpu\n",
            "param swinViT.layers3.0.blocks.1.attn.qkv.weight cpu\n",
            "param swinViT.layers3.0.blocks.1.attn.qkv.bias cpu\n",
            "param swinViT.layers3.0.blocks.1.attn.proj.weight cpu\n",
            "param swinViT.layers3.0.blocks.1.attn.proj.bias cpu\n",
            "param swinViT.layers3.0.blocks.1.norm2.weight cpu\n",
            "param swinViT.layers3.0.blocks.1.norm2.bias cpu\n",
            "param swinViT.layers3.0.blocks.1.mlp.linear1.weight cpu\n",
            "param swinViT.layers3.0.blocks.1.mlp.linear1.bias cpu\n",
            "param swinViT.layers3.0.blocks.1.mlp.linear2.weight cpu\n",
            "param swinViT.layers3.0.blocks.1.mlp.linear2.bias cpu\n",
            "param swinViT.layers3.0.downsample.reduction.weight cpu\n",
            "param swinViT.layers3.0.downsample.norm.weight cpu\n",
            "param swinViT.layers3.0.downsample.norm.bias cpu\n",
            "param swinViT.layers4.0.blocks.0.norm1.weight cpu\n",
            "param swinViT.layers4.0.blocks.0.norm1.bias cpu\n",
            "param swinViT.layers4.0.blocks.0.attn.relative_position_bias_table cpu\n",
            "param swinViT.layers4.0.blocks.0.attn.qkv.weight cpu\n",
            "param swinViT.layers4.0.blocks.0.attn.qkv.bias cpu\n",
            "param swinViT.layers4.0.blocks.0.attn.proj.weight cpu\n",
            "param swinViT.layers4.0.blocks.0.attn.proj.bias cpu\n",
            "param swinViT.layers4.0.blocks.0.norm2.weight cpu\n",
            "param swinViT.layers4.0.blocks.0.norm2.bias cpu\n",
            "param swinViT.layers4.0.blocks.0.mlp.linear1.weight cpu\n",
            "param swinViT.layers4.0.blocks.0.mlp.linear1.bias cpu\n",
            "param swinViT.layers4.0.blocks.0.mlp.linear2.weight cpu\n",
            "param swinViT.layers4.0.blocks.0.mlp.linear2.bias cpu\n",
            "param swinViT.layers4.0.downsample.reduction.weight cpu\n",
            "param swinViT.layers4.0.downsample.norm.weight cpu\n",
            "param swinViT.layers4.0.downsample.norm.bias cpu\n",
            "param encoder1.layer.conv1.conv.weight cpu\n",
            "param encoder1.layer.conv2.conv.weight cpu\n",
            "param encoder1.layer.conv3.conv.weight cpu\n",
            "param encoder2.layer.conv1.conv.weight cpu\n",
            "param encoder2.layer.conv2.conv.weight cpu\n",
            "param encoder3.layer.conv1.conv.weight cpu\n",
            "param encoder3.layer.conv2.conv.weight cpu\n",
            "param encoder4.layer.conv1.conv.weight cpu\n",
            "param encoder4.layer.conv2.conv.weight cpu\n",
            "param encoder10.layer.conv1.conv.weight cpu\n",
            "param encoder10.layer.conv2.conv.weight cpu\n",
            "param decoder5.transp_conv.conv.weight cpu\n",
            "param decoder5.conv_block.conv1.conv.weight cpu\n",
            "param decoder5.conv_block.conv2.conv.weight cpu\n",
            "param decoder5.conv_block.conv3.conv.weight cpu\n",
            "param decoder4.transp_conv.conv.weight cpu\n",
            "param decoder4.conv_block.conv1.conv.weight cpu\n",
            "param decoder4.conv_block.conv2.conv.weight cpu\n",
            "param decoder4.conv_block.conv3.conv.weight cpu\n",
            "param decoder3.transp_conv.conv.weight cpu\n",
            "param decoder3.conv_block.conv1.conv.weight cpu\n",
            "param decoder3.conv_block.conv2.conv.weight cpu\n",
            "param decoder3.conv_block.conv3.conv.weight cpu\n",
            "param decoder2.transp_conv.conv.weight cpu\n",
            "param decoder2.conv_block.conv1.conv.weight cpu\n",
            "param decoder2.conv_block.conv2.conv.weight cpu\n",
            "param decoder2.conv_block.conv3.conv.weight cpu\n",
            "param decoder1.transp_conv.conv.weight cpu\n",
            "param decoder1.conv_block.conv1.conv.weight cpu\n",
            "param decoder1.conv_block.conv2.conv.weight cpu\n",
            "param decoder1.conv_block.conv3.conv.weight cpu\n",
            "param out.conv.conv.weight cpu\n",
            "param out.conv.conv.bias cpu\n",
            "buffer swinViT.layers1.0.blocks.0.attn.relative_position_index cpu\n",
            "buffer swinViT.layers1.0.blocks.1.attn.relative_position_index cpu\n",
            "buffer swinViT.layers2.0.blocks.0.attn.relative_position_index cpu\n",
            "buffer swinViT.layers2.0.blocks.1.attn.relative_position_index cpu\n",
            "buffer swinViT.layers3.0.blocks.0.attn.relative_position_index cpu\n",
            "buffer swinViT.layers3.0.blocks.1.attn.relative_position_index cpu\n",
            "buffer swinViT.layers4.0.blocks.0.attn.relative_position_index cpu\n",
            "DataParallel requested but only <=1 GPU found — skipping DataParallel (use single-GPU).\n",
            "Model device (example param): cpu\n",
            "Is DataParallel: False\n",
            "Total params: 60.360 M, Trainable: 60.360 M\n",
            "[gdrive] Failed to load token.json: name 'pickle' is not defined\n",
            "Drive configured? False False\n",
            "[load] Model weights loaded (strict=False). Missing: 0, Unexpected: 0.\n",
            "[load] Optimizer state loaded.\n",
            "{'missing_keys': [], 'unexpected_keys': [], 'loaded_param_count': 147, 'notes': []}\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем главный девайс, который использует DataParallel (device_ids[0]) или MAIN_DEVICE\n",
        "if isinstance(model, nn.DataParallel):\n",
        "    dp_first = torch.device(f\"cuda:{model.device_ids[0]}\")\n",
        "    # Переместим именно внутренний модуль на этот девайс\n",
        "    model.module.to(dp_first)\n",
        "    main_dev = dp_first\n",
        "else:\n",
        "    model.to(MAIN_DEVICE)\n",
        "    main_dev = MAIN_DEVICE\n",
        "\n",
        "# Проверка\n",
        "for n,p in (model.module.named_parameters() if isinstance(model, nn.DataParallel) else model.named_parameters()):\n",
        "    if p.device != main_dev:\n",
        "        print(\"STILL WRONG:\", n, p.device)\n",
        "\n",
        "print(\"Model ready on\", main_dev)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:45.271771Z",
          "iopub.execute_input": "2025-11-19T20:24:45.272063Z",
          "iopub.status.idle": "2025-11-19T20:24:45.281098Z",
          "shell.execute_reply.started": "2025-11-19T20:24:45.272041Z",
          "shell.execute_reply": "2025-11-19T20:24:45.280322Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBDytcf61_l7",
        "outputId": "2ca105a8-55ee-4946-df7e-c0bf37043cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready on cpu\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/checkpoints\"\n",
        "\n",
        "ROOT_DIR = \"/content/checkpoints\""
      ],
      "metadata": {
        "id": "eoV8dOa038v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = {\"epochs\": [], \"train_loss\": [], \"val_loss\": [], \"val_f1\": [], \"val_precision\": [], \"val_recall\": [], \"lr\": [], \"saved_checkpoints\": []}\n",
        "best_val_f1 = -1\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    print(f\"\\n=== Epoch {epoch}/{NUM_EPOCHS} ===\")\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, epoch, scaler, MAIN_DEVICE, accumulation_steps=1)\n",
        "    val_loss, val_f1, val_prec, val_rec = validate(model, val_loader, MAIN_DEVICE)\n",
        "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | \"\n",
        "        f\"F1: {val_f1 if not np.isnan(val_f1) else 'nan'} | Prec: {val_prec if not np.isnan(val_prec) else 'nan'} | \"\n",
        "        f\"Rec: {val_rec if not np.isnan(val_rec) else 'nan'} | LR: {current_lr:.2e}\"\n",
        "    )\n",
        "\n",
        "    # === save checkpoint locally ===\n",
        "    model_to_save = unwrap_model(model)\n",
        "    ckpt_name = f\"checkpoint_epoch_{epoch}.pth\"\n",
        "    ckpt_path_local = os.path.join(ROOT_DIR, ckpt_name)\n",
        "    checkpoint = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model_to_save.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"val_f1\": val_f1,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_precision\": val_prec,\n",
        "        \"val_recall\": val_rec,\n",
        "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"used_model_params\": used_params,\n",
        "    }\n",
        "    torch.save(checkpoint, ckpt_path_local)\n",
        "    print(f\"[save] Saved checkpoint locally: {ckpt_path_local} (size={os.path.getsize(ckpt_path_local)} bytes)\")\n",
        "\n",
        "    # update best\n",
        "    if (not np.isnan(val_f1) and val_f1 > best_val_f1):\n",
        "        best_val_f1 = val_f1\n",
        "        best_path_local = os.path.join(ROOT_DIR, \"best_checkpoint.pth\")\n",
        "        torch.save(checkpoint, best_path_local)\n",
        "        print(f\"[save] Updated best checkpoint: {best_path_local} (size={os.path.getsize(best_path_local)} bytes)\")\n",
        "\n",
        "    # update history\n",
        "    history[\"epochs\"].append(epoch)\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_f1\"].append(val_f1)\n",
        "    history[\"val_precision\"].append(val_prec)\n",
        "    history[\"val_recall\"].append(val_rec)\n",
        "    history[\"lr\"].append(current_lr)\n",
        "    history[\"saved_checkpoints\"].append(ckpt_path_local)\n",
        "\n",
        "    # save history JSON\n",
        "    history_path = os.path.join(ROOT_DIR, \"training_history.json\")\n",
        "    try:\n",
        "        with open(history_path, \"w\", encoding=\"utf-8\") as fh:\n",
        "            json.dump(history, fh, ensure_ascii=False, indent=2)\n",
        "        print(f\"[save] Saved history JSON: {history_path} (size={os.path.getsize(history_path)} bytes)\")\n",
        "    except Exception as e:\n",
        "        print(\"[save] Failed to save training_history.json:\", e)\n",
        "\n",
        "    # save loss plot\n",
        "    loss_plot_path = os.path.join(ROOT_DIR, \"training_loss.png\")\n",
        "    try:\n",
        "        plt.figure(figsize=(8,5))\n",
        "        epochs_range = list(range(1, len(history[\"train_loss\"]) + 1))\n",
        "        plt.plot(epochs_range, history[\"train_loss\"], label=\"Train Loss\")\n",
        "        plt.plot(epochs_range, history[\"val_loss\"], label=\"Val Loss\")\n",
        "        plt.title(\"Training and Validation Loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(loss_plot_path)\n",
        "        plt.close()\n",
        "        print(f\"[save] Saved loss plot: {loss_plot_path} (size={os.path.getsize(loss_plot_path)} bytes)\")\n",
        "    except Exception as e:\n",
        "        loss_plot_path = None\n",
        "        print(\"[save] Failed to plot/save loss figure:\", e)\n",
        "\n",
        "    # prepare upload list\n",
        "    to_upload = [ckpt_path_local, history_path]\n",
        "    if loss_plot_path:\n",
        "        to_upload.append(loss_plot_path)\n",
        "    if 'best_path_local' in locals():\n",
        "        to_upload.append(best_path_local)\n",
        "\n",
        "    # === Upload to Google Drive (each epoch) with diagnostics ===\n",
        "    print(f\"[upload] Drive configured? service={gdrive_service is not None}, folder_id={gdrive_folder_id is not None}\")\n",
        "    uploaded_any = False\n",
        "    if gdrive_service is not None and gdrive_folder_id is not None:\n",
        "        for p in to_upload:\n",
        "            ok = try_upload_file(gdrive_service, gdrive_folder_id, p)\n",
        "            uploaded_any = uploaded_any or ok\n",
        "        if uploaded_any:\n",
        "            print(\"[upload] One or more files uploaded successfully.\")\n",
        "        else:\n",
        "            print(\"[upload] No files were uploaded (see messages above).\")\n",
        "        print(\"Drive folder link:\", f\"https://drive.google.com/drive/folders/{gdrive_folder_id}\")\n",
        "    else:\n",
        "        print(\"[upload] Skipping upload: Drive not configured. Place token.json and rerun setup_gdrive_from_token().\")\n",
        "\n",
        "    # scheduler step\n",
        "    if scheduler is not None:\n",
        "        try:\n",
        "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                scheduler.step(val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "        except Exception as e:\n",
        "            print(\"Scheduler step failed:\", e)\n",
        "\n",
        "print(\"Training finished. Best val F1:\", best_val_f1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-19T20:24:50.910091Z",
          "iopub.execute_input": "2025-11-19T20:24:50.910438Z",
          "iopub.status.idle": "2025-11-19T20:24:53.450147Z",
          "shell.execute_reply.started": "2025-11-19T20:24:50.910400Z",
          "shell.execute_reply": "2025-11-19T20:24:53.449027Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "8f9364e306664b3292f4f265acf1dc12",
            "562bff6f9de340b89040d0dae3d483f8",
            "598d6fed89804f3b9474b2fa1261ba2a",
            "f5a708757c7a43b19e6f653ca5a02839",
            "d31170e4b2ca449590ce4d7a4cde09cf",
            "f4bb191b04dc4e51b4f6ee673eaa616c",
            "f521e1d622af4837887446e992d3fafe",
            "59520e7292c34009a63384a325050882",
            "50b58a9a2fb54376aabe227dfb4c3f30",
            "3c805d808e4046c2a390a8f65f86812c",
            "b41867b67c86496fa6a71930a154adba"
          ]
        },
        "id": "PhMbo3Hg1_l7",
        "outputId": "1963a247-4cf7-4e4e-8e3a-314e1a535dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Epoch 1/20 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train E1:   0%|          | 0/1596 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f9364e306664b3292f4f265acf1dc12"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}