{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-16T15:06:54.779001Z",
     "iopub.status.busy": "2025-10-16T15:06:54.778434Z",
     "iopub.status.idle": "2025-10-16T15:08:14.923329Z",
     "shell.execute_reply": "2025-10-16T15:08:14.922511Z",
     "shell.execute_reply.started": "2025-10-16T15:06:54.778943Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting monai\n",
      "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\n",
      "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.1->monai)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->monai) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->monai) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\n",
      "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed monai-1.5.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T15:08:14.925369Z",
     "iopub.status.busy": "2025-10-16T15:08:14.925122Z",
     "iopub.status.idle": "2025-10-16T15:08:49.716584Z",
     "shell.execute_reply": "2025-10-16T15:08:49.715914Z",
     "shell.execute_reply.started": "2025-10-16T15:08:14.925346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
      "2025-10-16 15:08:37.865272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760627318.032519      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760627318.079484      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import requests\n",
    "from typing import Dict, Optional\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm  \n",
    "    _has_tqdm = True\n",
    "except ImportError:\n",
    "    _has_tqdm = False\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "# или попробовать:\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score, f1_score, jaccard_score\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import inspect\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import monai\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:45:09.953825Z",
     "iopub.status.busy": "2025-10-21T17:45:09.953486Z",
     "iopub.status.idle": "2025-10-21T17:45:10.682633Z",
     "shell.execute_reply": "2025-10-21T17:45:10.681477Z",
     "shell.execute_reply.started": "2025-10-21T17:45:09.953792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import gdown\n",
    "import numpy as np\n",
    "\n",
    "def download_and_unpack_gdrive_gdown(url_or_id, dest_folder='.', out_filename=None,\n",
    "                                     save_npy=False, quiet=False):\n",
    "    \"\"\"\n",
    "    Скачивает файл с Google Drive через gdown и распаковывает\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "    # если передали только id — соберём URL\n",
    "    if re.fullmatch(r\"[A-Za-z0-9_-]{10,}\", url_or_id):\n",
    "        url = f\"https://drive.google.com/uc?id={url_or_id}\"\n",
    "    else:\n",
    "        url = url_or_id\n",
    "\n",
    "    # имя выходного файла\n",
    "    if out_filename is None:\n",
    "        # попытка взять имя из URL, иначе дать дефолт\n",
    "        if \"id=\" in url:\n",
    "            out_filename = f\"downloaded_{url.split('id=')[-1]}.bin\"\n",
    "        else:\n",
    "            out_filename = os.path.basename(url) or \"downloaded_file.bin\"\n",
    "\n",
    "    out_path = os.path.join(dest_folder, out_filename)\n",
    "\n",
    "    # Скачиваем\n",
    "    if not os.path.exists(out_path):\n",
    "        gdown.download(url, out_path, quiet=quiet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:45:10.685708Z",
     "iopub.status.busy": "2025-10-21T17:45:10.685013Z",
     "iopub.status.idle": "2025-10-21T17:46:08.893608Z",
     "shell.execute_reply": "2025-10-21T17:46:08.892588Z",
     "shell.execute_reply.started": "2025-10-21T17:45:10.685668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ji5Vo4ZrAmJFALToEE6z6cQPhPMuzpTR\n",
      "From (redirected): https://drive.google.com/uc?id=1ji5Vo4ZrAmJFALToEE6z6cQPhPMuzpTR&confirm=t&uuid=41e60ff0-df8c-435a-bbd5-8abbce7d3262\n",
      "To: /kaggle/working/seis_train.npz\n",
      "100%|██████████| 7.77G/7.77G [00:56<00:00, 138MB/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_id = \"1NOUwAFtU_1KIlf8mQtB5xwSY-3NtYnDw\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "download_and_unpack_gdrive_gdown(url_or_id=url,\n",
    "                                           dest_folder=\"/kaggle/working\",\n",
    "                                           out_filename=\"seis_train.npz\",\n",
    "                                           quiet=False)\n",
    "\n",
    "out_path = os.path.join(\"/kaggle/working\", \"seis_train.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:46:08.895003Z",
     "iopub.status.busy": "2025-10-21T17:46:08.894668Z",
     "iopub.status.idle": "2025-10-21T17:46:50.177820Z",
     "shell.execute_reply": "2025-10-21T17:46:50.176846Z",
     "shell.execute_reply.started": "2025-10-21T17:46:08.894973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1ZQuC4ndHs_YphJOJrWTfZGbShbhflzTs\n",
      "From (redirected): https://drive.google.com/uc?id=1ZQuC4ndHs_YphJOJrWTfZGbShbhflzTs&confirm=t&uuid=2b1ebb99-1c6c-4f8f-a75b-44fe0c8deb97\n",
      "To: /kaggle/working/fault_train.npz\n",
      "100%|██████████| 8.01M/8.01M [00:00<00:00, 99.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_id = \"1QHE1gn7B8Zt99Cw1KDwyfNv6wqhM5h49\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "fault_val = download_and_unpack_gdrive_gdown(url_or_id=url,\n",
    "                                           dest_folder=\"/kaggle/working\",\n",
    "                                           out_filename=\"fault_train.npz\",\n",
    "                                           quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:46:50.178895Z",
     "iopub.status.busy": "2025-10-21T17:46:50.178585Z",
     "iopub.status.idle": "2025-10-21T17:47:06.904438Z",
     "shell.execute_reply": "2025-10-21T17:47:06.903538Z",
     "shell.execute_reply.started": "2025-10-21T17:46:50.178867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1JadBTLzPPneg0gZlafJfpR0n8M5OJA7J\n",
      "From (redirected): https://drive.google.com/uc?id=1JadBTLzPPneg0gZlafJfpR0n8M5OJA7J&confirm=t&uuid=4f5569db-3bcc-4b1c-b0fa-f8a12c8198b6\n",
      "To: /kaggle/working/seis_val.npz\n",
      "100%|██████████| 2.27G/2.27G [00:15<00:00, 148MB/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_id = \"1vVOkYAZkq08CtWosLd27Py4quvAaTjOa\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "fault_val = download_and_unpack_gdrive_gdown(url_or_id=url,\n",
    "                                           dest_folder=\"/kaggle/working\",\n",
    "                                           out_filename=\"seis_val.npz\",\n",
    "                                           quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:47:06.907373Z",
     "iopub.status.busy": "2025-10-21T17:47:06.907043Z",
     "iopub.status.idle": "2025-10-21T17:47:29.667021Z",
     "shell.execute_reply": "2025-10-21T17:47:29.665890Z",
     "shell.execute_reply.started": "2025-10-21T17:47:06.907342Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1B86e1OwsaUg7GI4WQryXeVNFBFqETBPM\n",
      "To: /kaggle/working/fault_val.npz\n",
      "100%|██████████| 2.21M/2.21M [00:00<00:00, 169MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_id = \"1YIeB6J69RUozpKwWa84m8ZXgpaQMWmP7\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "fault_val = download_and_unpack_gdrive_gdown(url_or_id=url,\n",
    "                                           dest_folder=\"/kaggle/working\",\n",
    "                                           out_filename=\"fault_val.npz\",\n",
    "                                           quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T15:11:58.439299Z",
     "iopub.status.busy": "2025-10-16T15:11:58.439027Z",
     "iopub.status.idle": "2025-10-16T15:12:10.052310Z",
     "shell.execute_reply": "2025-10-16T15:12:10.051473Z",
     "shell.execute_reply.started": "2025-10-16T15:11:58.439273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1bKLjIzaGMm8zWyYZhOob6-xKL2_qV5YT\n",
      "From (redirected): https://drive.google.com/uc?id=1bKLjIzaGMm8zWyYZhOob6-xKL2_qV5YT&confirm=t&uuid=677ee9db-b134-4fa5-ac45-64e9388ff70a\n",
      "To: /kaggle/working/checkpoint.pth\n",
      "100%|██████████| 731M/731M [00:09<00:00, 80.3MB/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_id = \"1bKLjIzaGMm8zWyYZhOob6-xKL2_qV5YT\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "fault_val = download_and_unpack_gdrive_gdown(url_or_id=url,\n",
    "                                           dest_folder=\"/kaggle/working\",\n",
    "                                           out_filename=\"checkpoint.pth\",\n",
    "                                           quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:47:29.671260Z",
     "iopub.status.busy": "2025-10-21T17:47:29.670961Z",
     "iopub.status.idle": "2025-10-21T17:47:29.704785Z",
     "shell.execute_reply": "2025-10-21T17:47:29.703694Z",
     "shell.execute_reply.started": "2025-10-21T17:47:29.671231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Union, Sequence, Tuple, Optional, Dict, Iterable\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "class SeisFaultDataset:\n",
    "    \"\"\"\n",
    "    Датасет для пар (сейсмика, fault) в виде 3D numpy-массивов.\n",
    "\n",
    "    Поддерживаемые источники:\n",
    "    - путь к .npz файлу (будет открыт через np.load(..., mmap_mode='r'))\n",
    "    - dict-like mapping имя -> np.ndarray\n",
    "\n",
    "    Парирование:\n",
    "    - если pairs не переданы, автоматически берётся отсортированное пересечение ключей\n",
    "      между seismic и fault источниками. Если пересечение пусто — бросается исключение.\n",
    "\n",
    "    Основные опции:\n",
    "    - target_shape: размер кропа (z,y,x)\n",
    "    - random_crop: True — случайные кропы, False — кропы с нулевого/центрального начала\n",
    "    - seed: для детерминированности\n",
    "    - normalize_seis: применять z-score нормализацию к сейсмике\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        seis_source: Union[str, Dict[str, np.ndarray]],\n",
    "        fault_source: Union[str, Dict[str, np.ndarray]],\n",
    "        pairs: Optional[Sequence[Tuple[str, str]]] = None,\n",
    "        target_shape: Tuple[int, int, int] = (128, 128, 128),\n",
    "        random_crop: bool = True,\n",
    "        seed: Optional[int] = None,\n",
    "        normalize_seis: bool = True,\n",
    "    ):\n",
    "        # параметры\n",
    "        self.target_shape = tuple(int(x) for x in target_shape)\n",
    "        if len(self.target_shape) != 3:\n",
    "            raise ValueError(\"target_shape должен быть кортежем длины 3\")\n",
    "        self.random_crop = bool(random_crop)\n",
    "        self.normalize_seis = bool(normalize_seis)\n",
    "        self._rng = random.Random(seed)\n",
    "\n",
    "        # загрузка источников (path -> npz mmap или оставляем dict)\n",
    "        self._seis_npz = None\n",
    "        self._fault_npz = None\n",
    "\n",
    "        if isinstance(seis_source, str):\n",
    "            if not os.path.exists(seis_source):\n",
    "                raise FileNotFoundError(seis_source)\n",
    "            self._seis_npz = np.load(seis_source, mmap_mode='r')\n",
    "            seis_source = self._seis_npz\n",
    "\n",
    "        if isinstance(fault_source, str):\n",
    "            if not os.path.exists(fault_source):\n",
    "                raise FileNotFoundError(fault_source)\n",
    "            self._fault_npz = np.load(fault_source, mmap_mode='r')\n",
    "            fault_source = self._fault_npz\n",
    "\n",
    "        # ожидаем mapping name->ndarray\n",
    "        self.seis_source = seis_source\n",
    "        self.fault_source = fault_source\n",
    "\n",
    "        # парами: либо явно, либо пересечение ключей\n",
    "        if pairs is not None:\n",
    "            self.pairs = list(pairs)\n",
    "        else:\n",
    "            seis_keys = self._keys_from_source(self.seis_source)\n",
    "            fault_keys = self._keys_from_source(self.fault_source)\n",
    "            common = sorted(set(seis_keys).intersection(fault_keys))\n",
    "            if not common:\n",
    "                raise ValueError(\"Нет общих ключей между seismic и fault источниками\")\n",
    "            # пары (имя, имя)\n",
    "            self.pairs = [(k, k) for k in common]\n",
    "\n",
    "        if len(self.pairs) == 0:\n",
    "            raise ValueError(\"No pairs available\")\n",
    "\n",
    "    # ---- Вспомогательные методы ----\n",
    "\n",
    "    def _keys_from_source(self, src):\n",
    "        \"\"\"Возвращает список ключей для mapping-источника или .files для npz.\"\"\"\n",
    "        if hasattr(src, 'files'):\n",
    "            return list(src.files)\n",
    "        if isinstance(src, dict):\n",
    "            return list(src.keys())\n",
    "        # obj, у которого можно взять ключи через итерацию\n",
    "        try:\n",
    "            return list(src.keys())\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Unsupported source type: {type(src)}\")\n",
    "\n",
    "    def _get_array(self, src, key):\n",
    "        \"\"\"Простая загрузка массива; ожидаем numpy.ndarray 3D.\"\"\"\n",
    "        arr = src[key]\n",
    "        if not isinstance(arr, np.ndarray):\n",
    "            # попытка конвертации (обычно не нужна)\n",
    "            arr = np.asarray(arr)\n",
    "        if arr.ndim != 3:\n",
    "            raise ValueError(f\"Ключ {key}: ожидается 3D массив, получено {arr.ndim}D\")\n",
    "        return arr\n",
    "\n",
    "    def _compute_crop_start(self, shape: Tuple[int, int, int]) -> Tuple[int, int, int]:\n",
    "        \"\"\"Вычислить стартовые индексы для кропа (случайно или ноль/центр).\"\"\"\n",
    "        starts = []\n",
    "        for i in range(3):\n",
    "            max_start = shape[i] - self.target_shape[i]\n",
    "            if max_start <= 0:\n",
    "                starts.append(0)\n",
    "            else:\n",
    "                if self.random_crop:\n",
    "                    starts.append(self._rng.randint(0, max_start))\n",
    "                else:\n",
    "                    # по умолчанию — центрированный кроп если есть запас\n",
    "                    starts.append(max_start // 2)\n",
    "        return tuple(starts)\n",
    "\n",
    "    def _zscore_normalize(self, vol: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Z-score нормализация (для сейсмики).\"\"\"\n",
    "        v = vol.astype(np.float32, copy=False)\n",
    "        mu = v.mean()\n",
    "        sigma = v.std()\n",
    "        eps = 1e-8\n",
    "        return (v - mu) / (sigma + eps)\n",
    "\n",
    "    # ---- интерфейс Dataset ----\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"Вернёт (seis_crop, fault_crop, meta).\"\"\"\n",
    "        if idx < 0:\n",
    "            idx = len(self) + idx\n",
    "        seis_key, fault_key = self.pairs[idx]\n",
    "\n",
    "        seis = self._get_array(self.seis_source, seis_key)\n",
    "        fault = self._get_array(self.fault_source, fault_key)\n",
    "\n",
    "        # берем кроп по форме seismic-а\n",
    "        starts = self._compute_crop_start(seis.shape)\n",
    "        slices = tuple(slice(st, st + ts) for st, ts in zip(starts, self.target_shape))\n",
    "\n",
    "        seis_crop = seis[slices]\n",
    "        fault_crop = fault[slices]\n",
    "\n",
    "        if self.normalize_seis:\n",
    "            seis_crop = self._zscore_normalize(seis_crop)\n",
    "\n",
    "        meta = {\n",
    "            \"seis_key\": seis_key,\n",
    "            \"fault_key\": fault_key,\n",
    "            \"crop_start\": starts,\n",
    "            \"original_shapes\": (seis.shape, fault.shape),\n",
    "        }\n",
    "        return seis_crop, fault_crop, meta\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Закрыть mmap .npz если он был открыт.\"\"\"\n",
    "        if self._seis_npz is not None:\n",
    "            try:\n",
    "                self._seis_npz.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "            self._seis_npz = None\n",
    "        if self._fault_npz is not None:\n",
    "            try:\n",
    "                self._fault_npz.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "            self._fault_npz = None\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T17:47:29.706093Z",
     "iopub.status.busy": "2025-10-21T17:47:29.705812Z",
     "iopub.status.idle": "2025-10-21T17:53:28.282846Z",
     "shell.execute_reply": "2025-10-21T17:53:28.281336Z",
     "shell.execute_reply.started": "2025-10-21T17:47:29.706073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = SeisFaultDataset(\"/kaggle/working/seis_train.npz\", \"/kaggle/working/fault_train.npz\", \n",
    "                      target_shape=(128,128,128), seed=42)\n",
    "\n",
    "val_ds = SeisFaultDataset(\"/kaggle/working/seis_val.npz\", \"/kaggle/working/fault_val.npz\", \n",
    "                      target_shape=(128,128,128), seed=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T15:16:00.367333Z",
     "iopub.status.busy": "2025-10-16T15:16:00.367059Z",
     "iopub.status.idle": "2025-10-16T15:16:00.379886Z",
     "shell.execute_reply": "2025-10-16T15:16:00.379074Z",
     "shell.execute_reply.started": "2025-10-16T15:16:00.367308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(path, model, optimizer=None, epoch=None, extra=None):\n",
    "    \"\"\"\n",
    "    Корректно сохраняет state_dict модели (без 'module.'), optimizer и мета.\n",
    "    \"\"\"\n",
    "    model_to_save = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    ckpt = {\"epoch\": epoch, \"model_state_dict\": model_to_save.state_dict()}\n",
    "    if optimizer is not None:\n",
    "        ckpt[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
    "    if extra:\n",
    "        ckpt.update(extra)\n",
    "    torch.save(ckpt, path)\n",
    "\n",
    "\n",
    "def _strip_module_prefix(state_dict):\n",
    "    # удаляем все префиксы \"module.\" (на случай многократных вхождений)\n",
    "    new_state = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith(\"module.\"):\n",
    "            new_state[k[len(\"module.\"):]] = v\n",
    "        else:\n",
    "            new_state[k] = v\n",
    "    return new_state\n",
    "\n",
    "\n",
    "def _move_optimizer_state_to_device(opt_state, device):\n",
    "    # переносим все тензоры в optimizer.state на нужное устройство\n",
    "    for state in opt_state.values():\n",
    "        for k, v in list(state.items()):\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.to(device)\n",
    "\n",
    "\n",
    "def load_checkpoint(\n",
    "    path,\n",
    "    model,\n",
    "    optimizer=None,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    strict=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Загрузка чекпойнта с учётом DataParallel\n",
    "    \"\"\"\n",
    "    # безопасно загружаем на cpu, а потом переносим model/opt на device\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    if verbose:\n",
    "        print(f\"[ckpt] loaded checkpoint type={type(ckpt)}\")\n",
    "\n",
    "    # извлекаем state_dict модели\n",
    "    if isinstance(ckpt, dict):\n",
    "        state = ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\", None))\n",
    "        if state is None:\n",
    "            # возможно, чекпойнт — это просто state_dict\n",
    "            # проверим: если все значения — тензоры, считаем это state_dict\n",
    "            if all(isinstance(v, torch.Tensor) for v in ckpt.values()):\n",
    "                state = ckpt\n",
    "            else:\n",
    "                raise RuntimeError(\"Checkpoint dict doesn't contain recognizable model state.\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Checkpoint seems to contain a pickled model object. \"\n",
    "                           \"Prefer saving state_dict instead of full model object.\")\n",
    "\n",
    "    # убираем 'module.' если нужно\n",
    "    state = _strip_module_prefix(state)\n",
    "\n",
    "    # проверяем размеры ключей и предупреждаем о несоответствиях до загрузки\n",
    "    model_to_load = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    model_state = model_to_load.state_dict()\n",
    "    mismatched_shapes = []\n",
    "    for k, v in state.items():\n",
    "        if k in model_state and v.shape != model_state[k].shape:\n",
    "            mismatched_shapes.append((k, v.shape, model_state[k].shape))\n",
    "    if mismatched_shapes and verbose:\n",
    "        print(\"[ckpt] WARNING: found tensors with mismatched shapes (ckpt vs model):\")\n",
    "        for k, s_ckpt, s_model in mismatched_shapes[:10]:\n",
    "            print(f\"   {k}: ckpt{tuple(s_ckpt)} != model{tuple(s_model)}\")\n",
    "        if len(mismatched_shapes) > 10:\n",
    "            print(f\"   ... and {len(mismatched_shapes)-10} more\")\n",
    "\n",
    "    # загружаем state_dict (strict может быть False, чтобы не падать)\n",
    "    load_res = model_to_load.load_state_dict(state, strict=strict)\n",
    "    if verbose:\n",
    "        # load_state_dict возвращает NamedTuple(missing_keys, unexpected_keys)\n",
    "        print(\"[ckpt] load_state_dict result:\", load_res)\n",
    "\n",
    "    # переносим модель на device\n",
    "    model.to(device)\n",
    "\n",
    "    # если есть optimizer и он сохранялся — грузим и переносим тензоры оптимизатора\n",
    "    if optimizer is not None and isinstance(ckpt, dict) and \"optimizer_state_dict\" in ckpt:\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "        _move_optimizer_state_to_device(optimizer.state, device)\n",
    "        if verbose:\n",
    "            print(\"[ckpt] optimizer state loaded and moved to\", device)\n",
    "\n",
    "    return ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def build_swinunetr_from_params(params: Dict[str, Any], in_ch: int = 1, out_ch: int = 1, device: torch.device = None) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Построить SwinUNETR из словаря params, отфильтровав те параметры конструктора,\n",
    "    которые разрешены сигнатурой класса.\n",
    "\n",
    "    Возвращает модель на указанном device. Если доступно несколько GPU — оборачивает в DataParallel.\n",
    "    \"\"\"\n",
    "    device = DEVICE if device is None else device\n",
    "    sig = inspect.signature(SwinUNETR.__init__)\n",
    "    allowed = {p for p in sig.parameters.keys() if p not in (\"self\", \"in_channels\", \"out_channels\")}\n",
    "    call_kwargs = {k: v for k, v in params.items() if k in allowed}\n",
    "    model = SwinUNETR(in_ch, out_ch, **call_kwargs)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"[build] Wrapping model with DataParallel on {torch.cuda.device_count()} GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def diag_forward_shapes(model: nn.Module, imgs: torch.Tensor, module_name_filters: Optional[List[str]] = None, device: torch.device = None) -> List[Tuple[str, Tuple[int, ...]]]:\n",
    "    \"\"\"\n",
    "    Запускает быстрый forward (без вычисления градиентов) и собирает формы outputs\n",
    "    от модулей, имена которых содержат любую подстроку из module_name_filters.\n",
    "\n",
    "    Возвращает список (ClassName, shape).\n",
    "    Работает корректно как для обычной модели, так и для DataParallel обёртки.\n",
    "    \"\"\"\n",
    "    device = DEVICE if device is None else device\n",
    "    shapes = []\n",
    "    handles = []\n",
    "\n",
    "    # если DataParallel — брать оригинальную модель для перебора модулей\n",
    "    actual = model.module if isinstance(model, nn.DataParallel) else model\n",
    "\n",
    "    def hook(module, inp, out):\n",
    "        # пытаемся взять shape у out\n",
    "        try:\n",
    "            shp = tuple(out.shape)\n",
    "            shapes.append((module.__class__.__name__, shp))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Регистрируем хуки на отфильтрованные модули\n",
    "    for name, mod in actual.named_modules():\n",
    "        if module_name_filters is None or any(f in name for f in module_name_filters):\n",
    "            try:\n",
    "                handles.append(mod.register_forward_hook(hook))\n",
    "            except Exception:\n",
    "                # некритично — пропустим модуль\n",
    "                pass\n",
    "\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _ = model(imgs.to(device))\n",
    "    except Exception as e:\n",
    "        # Если forward упал — всё равно вернём что успели собрать\n",
    "        # Для отладки можно пробросить исключение, но для авто- tune это полезно сохранять.\n",
    "        print(\"[diag_forward_shapes] forward failed:\", e)\n",
    "    finally:\n",
    "        for h in handles:\n",
    "            try:\n",
    "                h.remove()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return shapes\n",
    "\n",
    "\n",
    "def has_1x1x1_activation(shapes: List[Tuple[str, Tuple[int, ...]]]) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, есть ли среди собранных форм тензоры, у которых последние три размеры == (1,1,1).\n",
    "    Возвращает True если найдена такая активация.\n",
    "    \"\"\"\n",
    "    for clsname, shp in shapes:\n",
    "        if len(shp) >= 3 and shp[-3:] == (1, 1, 1):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def auto_adjust_and_build_model(sample_imgs: torch.Tensor,\n",
    "                                base_params: Dict[str, Any],\n",
    "                                max_attempts: int = 6,\n",
    "                                device: torch.device = None) -> Tuple[nn.Module, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Авто-подстройка параметров модели:\n",
    "    - Пытается создать модель с base_params.\n",
    "    - Делает быстрый forward diag; если где-то появляются активации с spatial (1,1,1) —\n",
    "      последовательно уменьшает глубины (depths) начиная с самого глубокого уровня.\n",
    "    - Если depths уже минимальны (все ==1), пробует уменьшить feature_size пополам до минимума 16.\n",
    "    - Повторяет до max_attempts раз и возвращает (model, used_params) при успехе.\n",
    "\n",
    "    Бросает RuntimeError при неудаче.\n",
    "    \"\"\"\n",
    "    device = DEVICE if device is None else device\n",
    "    params = dict(base_params)  # локальная копия\n",
    "    attempt = 0\n",
    "    last_err = None\n",
    "\n",
    "    while attempt < max_attempts:\n",
    "        attempt += 1\n",
    "        print(f\"[auto-tune] Attempt {attempt}: depths={params.get('depths')} feature_size={params.get('feature_size')}\")\n",
    "        # Попытка создать модель\n",
    "        try:\n",
    "            model = build_swinunetr_from_params(params, device=device)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(\"[auto-tune] Model instantiation failed:\", e)\n",
    "            # Если проблема в памяти — пробуем уменьшить feature_size\n",
    "            fs = params.get(\"feature_size\")\n",
    "            if isinstance(fs, int) and fs > 16:\n",
    "                params[\"feature_size\"] = max(16, fs // 2)\n",
    "                print(\"[auto-tune] Reducing feature_size ->\", params[\"feature_size\"])\n",
    "                torch.cuda.empty_cache()\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "        # Быстрая диагностика форм\n",
    "        shapes = diag_forward_shapes(model, sample_imgs, module_name_filters=[\"encoder\", \"decoder\"], device=device)\n",
    "        if not has_1x1x1_activation(shapes):\n",
    "            print(\"[auto-tune] Success — no 1x1x1 activations detected.\")\n",
    "            return model, params\n",
    "\n",
    "        # Найдена 1x1x1 активация — уменьшаем depths, начиная с конца\n",
    "        print(\"[auto-tune] Detected 1x1x1 activation — will try to reduce depths/feature_size.\")\n",
    "        depths = list(params.get(\"depths\", (2, 2, 2, 2)))\n",
    "        reduced = False\n",
    "        for i in range(len(depths) - 1, -1, -1):\n",
    "            if depths[i] > 1:\n",
    "                depths[i] = 1\n",
    "                reduced = True\n",
    "                break\n",
    "\n",
    "        if reduced:\n",
    "            params[\"depths\"] = tuple(depths)\n",
    "            print(\"[auto-tune] Reduced depths ->\", params[\"depths\"])\n",
    "            try:\n",
    "                del model\n",
    "            except Exception:\n",
    "                pass\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        # depths уже минимальны — пробуем уменьшить feature_size\n",
    "        fs = params.get(\"feature_size\", 48)\n",
    "        if isinstance(fs, int) and fs > 16:\n",
    "            params[\"feature_size\"] = max(16, fs // 2)\n",
    "            print(\"[auto-tune] Depths minimal — reducing feature_size ->\", params[\"feature_size\"])\n",
    "            try:\n",
    "                del model\n",
    "            except Exception:\n",
    "                pass\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        # Нечего уже уменьшать\n",
    "        try:\n",
    "            del model\n",
    "        except Exception:\n",
    "            pass\n",
    "        torch.cuda.empty_cache()\n",
    "        raise RuntimeError(\"Auto-tune failed: cannot remove 1x1x1 activations\")\n",
    "\n",
    "    # Если цикл закончился без успеха\n",
    "    raise RuntimeError(f\"Auto-tune failed after {max_attempts} attempts. Last error: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-16T15:16:00.381205Z",
     "iopub.status.busy": "2025-10-16T15:16:00.380935Z",
     "iopub.status.idle": "2025-10-16T16:26:43.027994Z",
     "shell.execute_reply": "2025-10-16T16:26:43.027090Z",
     "shell.execute_reply.started": "2025-10-16T15:16:00.381185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auto-tune] Attempt 1, depths=(2, 2, 2, 1)\n",
      "Using 2 GPUs!\n",
      "[auto-tune] OK — no 1x1x1 activations detected.\n",
      "Using MODEL_PARAMS (after auto-adjust): {'patch_size': (2, 2, 2), 'depths': (2, 2, 2, 1), 'num_heads': (3, 6, 12, 24), 'window_size': (7, 7, 7), 'qkv_bias': True, 'mlp_ratio': 4.0, 'feature_size': 48, 'drop_rate': 0.0, 'attn_drop_rate': 0.0, 'dropout_path_rate': 0.1, 'patch_norm': True, 'spatial_dims': 3}\n",
      "[ckpt] loaded checkpoint type=<class 'dict'>\n",
      "[ckpt] load_state_dict result: <All keys matched successfully>\n",
      "[ckpt] optimizer state loaded and moved to cuda\n",
      "Model param count: 60359563\n",
      "keys in ckpt but not in model: []\n",
      "keys in model but not in ckpt: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train E1: 100%|██████████| 1008/1008 [1:05:05<00:00,  3.87s/it, loss=1.05]\n",
      "Val: 100%|██████████| 288/288 [05:30<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train loss: 1.0538 | Val loss: 1.1489 | F1: 0.43850069631850125\n",
      "Best model updated: 0.43850069631850125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Best val Dice: 0.43850069631850125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, weight_bce=1.0, weight_dice=1.0):\n",
    "        super().__init__()\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.bce = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=torch.tensor([13.3], device=device)\n",
    "        )\n",
    "        self.dice = monai.losses.DiceLoss(sigmoid=True, squared_pred=False, reduction=\"mean\")\n",
    "        self.w_bce = weight_bce\n",
    "        self.w_dice = weight_dice\n",
    "    \n",
    "    def forward(self, logits, target):\n",
    "        if target.dim() == logits.dim() - 1:\n",
    "            target = target.unsqueeze(1)\n",
    "        return self.w_bce * self.bce(logits, target) + self.w_dice * self.dice(logits, target)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, loss_fn, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Train E{epoch}\")\n",
    "    \n",
    "    for i, batch in pbar:\n",
    "        if len(batch) == 3:\n",
    "            imgs, masks, metas = batch\n",
    "        else:\n",
    "            imgs, masks = batch\n",
    "        \n",
    "        imgs = imgs.unsqueeze(1).float()\n",
    "        masks = masks.unsqueeze(1).float()\n",
    "        \n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        masks = masks.to(DEVICE, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            outputs = model(imgs)\n",
    "        except ValueError as e:\n",
    "            msg = str(e)\n",
    "            if \"Expected more than 1 spatial element\" in msg:\n",
    "                raise RuntimeError(\"Runtime forward error: spatial dims too small. Consider increasing ROI or manual model changes.\\n\" + msg)\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += float(loss.item())\n",
    "        pbar.set_postfix(loss=running_loss / (i + 1))\n",
    "    \n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    loss_fn = CombinedLoss()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    total_pixels = 0\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Val\")\n",
    "    with torch.no_grad():\n",
    "        for i, batch in pbar:\n",
    "            if len(batch) == 3:\n",
    "                imgs, masks, metas = batch\n",
    "            else:\n",
    "                imgs, masks = batch\n",
    "\n",
    "            imgs = imgs.unsqueeze(1).float().to(DEVICE)\n",
    "            masks = masks.unsqueeze(1).float().to(DEVICE)\n",
    "\n",
    "            logits = sliding_window_inference(\n",
    "                inputs=imgs,\n",
    "                roi_size=ROI_SIZE,\n",
    "                sw_batch_size=SW_BATCH_SIZE,\n",
    "                predictor=model,\n",
    "                overlap=OVERLAP,\n",
    "            )\n",
    "\n",
    "            # loss\n",
    "            val_loss += float(loss_fn(logits, masks).item())\n",
    "\n",
    "            # preds\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            # приводим к 1D\n",
    "            preds_flat = preds.view(-1)\n",
    "            masks_flat = masks.view(-1)\n",
    "\n",
    "            # аккуратно считаем TP/FP/FN на GPU, затем переводим в int\n",
    "            TP += int(((preds_flat == 1.0) & (masks_flat == 1.0)).sum().item())\n",
    "            FP += int(((preds_flat == 1.0) & (masks_flat == 0.0)).sum().item())\n",
    "            FN += int(((preds_flat == 0.0) & (masks_flat == 1.0)).sum().item())\n",
    "\n",
    "            total_pixels += preds_flat.numel()\n",
    "\n",
    "    # усреднённый лосс по батчам\n",
    "    val_loss = val_loss / max(1, len(dataloader))\n",
    "\n",
    "    # F1 (без деления на ноль)\n",
    "    denom = 2 * TP + FP + FN\n",
    "    if denom == 0:\n",
    "        # нет позитивных пикселей ни в GT, ни в предсказаниях -> F1 не определён\n",
    "        val_f1 = float(\"nan\")\n",
    "    else:\n",
    "        val_f1 = 2.0 * TP / denom\n",
    "\n",
    "    return val_loss, val_f1\n",
    "\n",
    "\n",
    "ROI_SIZE = (128, 128, 128) \n",
    "LEARNING_RATE = 1e-4\n",
    "ROOT_DIR = \"./checkpoints\"\n",
    "SW_BATCH_SIZE = 2\n",
    "OVERLAP = 0.25\n",
    "\n",
    "MODEL_PARAMS = dict(\n",
    "    patch_size=(2, 2, 2),\n",
    "    depths=(2, 2, 2, 1),      \n",
    "    num_heads=(3, 6, 12, 24),\n",
    "    window_size=(7, 7, 7),\n",
    "    qkv_bias=True,\n",
    "    mlp_ratio=4.0,\n",
    "    feature_size=48,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.1,\n",
    "    patch_norm=True,\n",
    "    spatial_dims=3,\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "# детерминированный рандом-генератор для reproducibility\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(SEED)\n",
    "\n",
    "#train_ds, val_ds, out = torch.utils.data.random_split(ds, [train_len, val_len, out_len], generator=generator)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "try:\n",
    "    batch = next(iter(train_loader))\n",
    "except StopIteration:\n",
    "    raise RuntimeError(\"train_loader yielded no data for autotune\")\n",
    "imgs_sample = batch[0].unsqueeze(1).float() if isinstance(batch, (list, tuple)) else batch.unsqueeze(1).float()\n",
    "\n",
    "# auto-adjust and build model\n",
    "model, used_params = auto_adjust_and_build_model(imgs_sample, max_attempts=6)\n",
    "print(\"Using MODEL_PARAMS (after auto-adjust):\", used_params)\n",
    "\n",
    "ckpt_path = \"/kaggle/working/checkpoint.pth\"\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "ckpt = load_checkpoint(ckpt_path, model, optimizer=optimizer, device=DEVICE, strict=False, verbose=True)\n",
    "# после загрузки\n",
    "model_to_inspect = model.module if isinstance(model, nn.DataParallel) else model\n",
    "print(\"Model param count:\", sum(p.numel() for p in model_to_inspect.parameters()))\n",
    "# сравнить ключи чекпойнта и модели\n",
    "ckpt_state = ckpt.get(\"model_state_dict\", ckpt.get(\"state_dict\", ckpt))\n",
    "ckpt_keys = set(k.replace(\"module.\", \"\") for k in ckpt_state.keys())\n",
    "model_keys = set(model_to_inspect.state_dict().keys())\n",
    "print(\"keys in ckpt but not in model:\", sorted(list(ckpt_keys - model_keys))[:20])\n",
    "print(\"keys in model but not in ckpt:\", sorted(list(model_keys - ckpt_keys))[:20])\n",
    "\n",
    "\n",
    "loss_fn = CombinedLoss()\n",
    "best_val_dice = -1.0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_dices = []\n",
    "val_f1s = []\n",
    "val_aps = []\n",
    "val_ious = []\n",
    "\n",
    "best_val_dice = -1.0\n",
    "best_val_f1 = 0\n",
    "\n",
    "os.makedirs(ROOT_DIR, exist_ok=True)\n",
    "loss_plot_path = os.path.join(ROOT_DIR, \"training_loss.png\")\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, loss_fn, epoch)\n",
    "\n",
    "    val_loss, val_f1 = validate(model, val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} | Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | \"\n",
    "        f\"F1: {val_f1 if not np.isnan(val_f1) else 'nan'}\"\n",
    "    )\n",
    "\n",
    "    model_to_save = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model_to_save.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"val_f1\": val_f1,\n",
    "        \"val_loss\": val_loss,\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(ROOT_DIR, f\"checkpoint_epoch_{epoch}.pth\"))\n",
    "\n",
    "    # обновим лучший по F1\n",
    "    if (not np.isnan(val_f1) and val_f1 > best_val_f1):  \n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(checkpoint, os.path.join(ROOT_DIR, \"best_checkpoint.pth\"))\n",
    "        print(\"Best model updated:\", best_val_f1)\n",
    "         # обновляем исторические списки\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_f1s.append(val_f1)\n",
    "\n",
    "    # рисуем и сохраняем график loss (train + val)\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        epochs_range = list(range(1, len(train_losses) + 1))\n",
    "        plt.plot(epochs_range, train_losses, label=\"Train Loss\")\n",
    "        plt.plot(epochs_range, val_losses, label=\"Val Loss\")\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        # сохраняем в верхнюю директорию (ROOT_DIR)\n",
    "        plt.savefig(loss_plot_path)\n",
    "        plt.show()  # в ноутбуке Kaggle покажет график\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Failed to plot/save loss figure: {e}\")\n",
    "\n",
    "print(\"Training finished. Best val f1:\", best_val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
